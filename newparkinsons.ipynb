{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcyqbs0q4GGCTmk3JNITNb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "40b9988ea0f24629815a59c5ab47ddfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd5725f7b4f44906a131bcff38b419d4",
              "IPY_MODEL_073b5c8122424fa8bf3d7fdbd5ae050c",
              "IPY_MODEL_b713b18c6dea4f478daad444821386f9"
            ],
            "layout": "IPY_MODEL_6a3d0ce8cf5d4a44ad228051fad4f1d1"
          }
        },
        "dd5725f7b4f44906a131bcff38b419d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d0e8a94aae428082a94a27f81466e1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a8e96fe4cb5949749123ab4b87d80e7d",
            "value": "üìÅ‚ÄáTraversing‚Äádirectories‚Äáfor‚Äáds002778‚Äá:‚Äá"
          }
        },
        "073b5c8122424fa8bf3d7fdbd5ae050c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31375c8abb1a4406881912a2347e1e9e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dbbe744989f4759a028165b115de480",
            "value": 1
          }
        },
        "b713b18c6dea4f478daad444821386f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8b9861238d84748b5e522d88d0d9d11",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_be505bf343bd478d948f33ffd7ef9775",
            "value": "‚Äá328/?‚Äá[00:16&lt;00:00,‚Äá18.60‚Äáentities/s]"
          }
        },
        "6a3d0ce8cf5d4a44ad228051fad4f1d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10d0e8a94aae428082a94a27f81466e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e96fe4cb5949749123ab4b87d80e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31375c8abb1a4406881912a2347e1e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1dbbe744989f4759a028165b115de480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f8b9861238d84748b5e522d88d0d9d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be505bf343bd478d948f33ffd7ef9775": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vathsal14/NOVO-NEUROTECH/blob/main/newparkinsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "# Installs the 'requests' library, which is used for making HTTP requests in Python. It simplifies interacting with web services and APIs.\n",
        "# version: requests-2.32.3\n",
        "!pip install mne\n",
        "# Installs the 'mne' library, which is a powerful tool for processing, analyzing, and visualizing EEG, MEG, and other neurophysiological data.\n",
        "# version: mne-1.9.0\n",
        "!pip install pyedflib\n",
        "# Installs the 'pyedflib' library, which allows reading and writing of EDF (European Data Format) and BDF (Biosemi Data Format) files, commonly used in EEG data storage.\n",
        "# version: pyedflib-0.1.38\n",
        "!pip install openneuro-py\n",
        "# Installs the 'openneuro-py' library, a Python client for accessing and downloading datasets from OpenNeuro, a platform for neuroimaging data sharing.\n",
        "# aiofiles-24.1.0 graphql-core-3.2.5 openneuro-py-2024.2.0 sgqlc-16.4\n",
        "!pip install PyWavelets\n",
        "# Installs the 'PyWavelets' library, which provides wavelet transform functions for signal processing, including denoising, feature extraction, and compression.\n",
        "# version: PyWavelets-1.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zX9kQeDKEpb",
        "outputId": "df66fa5a-2040-4d76-c607-be4e14823583"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n",
            "Collecting pyedflib\n",
            "  Downloading pyedflib-0.1.39.tar.gz (2.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from pyedflib) (1.26.4)\n",
            "Building wheels for collected packages: pyedflib\n",
            "  Building wheel for pyedflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyedflib: filename=pyEDFlib-0.1.39-cp311-cp311-linux_x86_64.whl size=2624433 sha256=aed6fd2ef4e5805640109b0acd1f3dcdec14ede738c5371f3eca08fb7832f5c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/25/41/b9605de2c5973791e87828347971b06712b12a14add875bff6\n",
            "Successfully built pyedflib\n",
            "Installing collected packages: pyedflib\n",
            "Successfully installed pyedflib-0.1.39\n",
            "Collecting openneuro-py\n",
            "  Downloading openneuro_py-2024.2.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from openneuro-py)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.15 in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (0.28.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (4.3.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (2.32.3)\n",
            "Collecting sgqlc (from openneuro-py)\n",
            "  Downloading sgqlc-16.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (4.67.1)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (0.15.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.15->openneuro-py) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openneuro-py) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openneuro-py) (2.3.0)\n",
            "Collecting graphql-core<4.0.0,>=3.2.4 (from sgqlc->openneuro-py)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (8.1.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer[all]->openneuro-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer[all]->openneuro-py) (2.18.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.15->openneuro-py) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]->openneuro-py) (0.1.2)\n",
            "Downloading openneuro_py-2024.2.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading sgqlc-16.4-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphql-core, aiofiles, sgqlc, openneuro-py\n",
            "Successfully installed aiofiles-24.1.0 graphql-core-3.2.6 openneuro-py-2024.2.0 sgqlc-16.4\n",
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GCAEjAwO8QnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d26159c-7a78-4736-ccff-766d87001518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importing the Google Colab drive module\n",
        "from google.colab import drive\n",
        "# Mounting Google Drive to the Colab environment\n",
        "# This allows you to access files stored in your Google Drive directly from the Colab notebook.\n",
        "# The \"/content/drive\" is the directory where the Drive will be mounted.\n",
        "# After mounting, you can interact with your Drive files as if they were local files.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "# 'python-dotenv' is a library that allows you to manage environment variables from a `.env` file.\n",
        "# This is particularly useful for securely storing sensitive information such as API keys, database credentials, etc.\n",
        "# By using environment variables, you avoid hardcoding sensitive data directly in your code."
      ],
      "metadata": {
        "id": "lsSQtl4dKDqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddb64a60-e0f0-48d1-f73e-b9f54f7c4ddc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # The 'os' module is used to interact with the operating system, such as reading environment variables.\n",
        "from dotenv import load_dotenv  # 'load_dotenv' is used to load environment variables from a .env file.\n",
        "# Specify the path to the .env file\n",
        "# The .env file stores environment variables like API keys securely.\n",
        "# In this case, the .env file is located in the user's Google Drive.\n",
        "env_path = '/content/drive/My Drive/ColabEnvFiles/API_KEY.env'\n",
        "# Load the environment variables from the specified .env file\n",
        "load_dotenv(env_path)\n",
        "# Access the API key using the key name as defined in the .env file\n",
        "api_key = os.getenv(\"OPENNEURO_API_KEY\")\n",
        "# Check if the API key was successfully loaded\n",
        "if api_key:\n",
        "    print(\"API Key loaded successfully!\")  # Inform the user that the API key was loaded.\n",
        "else:\n",
        "    print(\"Failed to load API Key. Check your .env file and path.\")  # Error message if loading fails."
      ],
      "metadata": {
        "id": "dvPJONHsPIOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d496069-8c17-44a2-aeca-837b113276ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openneuro\n",
        "\n",
        "# Prompt the user to enter the dataset ID\n",
        "dataset_id = input(\"Enter the dataset ID (e.g., ds002778): \")\n",
        "\n",
        "# Validate the input\n",
        "if not dataset_id:\n",
        "    raise ValueError(\"Dataset ID must be provided.\")\n",
        "\n",
        "print(f\"Processing dataset: {dataset_id}\")\n",
        "\n",
        "# Function to create a directory\n",
        "def create_directory(dir_path):\n",
        "    try:\n",
        "        # Attempt to create the directory\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        print(f\"Directory created successfully at: {dir_path}\")\n",
        "    except PermissionError:\n",
        "        # Handle permission errors\n",
        "        print(f\"Permission denied: Unable to create directory at {dir_path}. Please check permissions.\")\n",
        "    except OSError as e:\n",
        "        # Handle other OS-related errors\n",
        "        print(f\"Error creating directory at {dir_path}: {e}\")\n",
        "    except Exception as e:\n",
        "        # Catch any unexpected errors\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Determine the target directory for the download\n",
        "target_dir = os.path.join(os.getcwd(), dataset_id)\n",
        "\n",
        "# Create the target directory\n",
        "create_directory(target_dir)\n",
        "\n",
        "# Download the entire dataset\n",
        "openneuro.download(dataset=dataset_id, target_dir=target_dir)\n",
        "\n",
        "print(f\"Dataset {dataset_id} downloaded successfully to {target_dir}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "40b9988ea0f24629815a59c5ab47ddfe",
            "dd5725f7b4f44906a131bcff38b419d4",
            "073b5c8122424fa8bf3d7fdbd5ae050c",
            "b713b18c6dea4f478daad444821386f9",
            "6a3d0ce8cf5d4a44ad228051fad4f1d1",
            "10d0e8a94aae428082a94a27f81466e1",
            "a8e96fe4cb5949749123ab4b87d80e7d",
            "31375c8abb1a4406881912a2347e1e9e",
            "1dbbe744989f4759a028165b115de480",
            "f8b9861238d84748b5e522d88d0d9d11",
            "be505bf343bd478d948f33ffd7ef9775"
          ]
        },
        "id": "q0PNakwqPQT8",
        "outputId": "1eaaa7b5-2394-4e4b-b0e3-671430288786"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the dataset ID (e.g., ds002778): ds002778\n",
            "Processing dataset: ds002778\n",
            "Directory created successfully at: /content/ds002778\n",
            "\n",
            "üëã Hello! This is openneuro-py 2024.2.0. Great to see you! ü§ó\n",
            "\n",
            "   üëâ Please report problems ü§Ø and bugs ü™≤ at\n",
            "      https://github.com/hoechenberger/openneuro-py/issues\n",
            "\n",
            "üåç Preparing to download ds002778 ‚Ä¶\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "üìÅ Traversing directories for ds002778 : 0 entities [00:00, ? entities/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40b9988ea0f24629815a59c5ab47ddfe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Retrieving up to 328 files (5 concurrent downloads). \n",
            "‚úÖ Finished downloading ds002778.\n",
            " \n",
            "üß† Please enjoy your brains.\n",
            " \n",
            "Dataset ds002778 downloaded successfully to /content/ds002778.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Path to dataset directory\n",
        "target_dir = '/content/ds002778'\n",
        "\n",
        "# Dictionary to store subject data\n",
        "subject_data = {}\n",
        "\n",
        "# Loop through subject folders\n",
        "for subject_folder in os.listdir(target_dir):\n",
        "\n",
        "    if subject_folder.startswith('sub-'):\n",
        "        subject_id = subject_folder.split('-')[1]\n",
        "        print(f\"\\nProcessing subject: {subject_id}\")\n",
        "\n",
        "        # Check if subject is Parkinson's or Healthy Control\n",
        "        if subject_id.startswith('pd'):\n",
        "            session_path = os.path.join(target_dir, subject_folder, 'ses-off', 'eeg')\n",
        "            session_type = 'ses-off'\n",
        "            json_path = os.path.join(target_dir, subject_folder, 'ses-off', 'beh')\n",
        "        elif subject_id.startswith('hc'):\n",
        "            session_path = os.path.join(target_dir, subject_folder, 'ses-hc', 'eeg')\n",
        "            session_type = 'ses-hc'\n",
        "            json_path = None  # No JSON for HC subjects\n",
        "        else:\n",
        "            print(f\"Unknown subject type for {subject_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        if not os.path.exists(session_path):\n",
        "            print(f\"No '{session_type}/eeg' folder found for subject {subject_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Find the EEG file (.bdf)\n",
        "        bdf_file = None\n",
        "        for file in os.listdir(session_path):\n",
        "            if file.endswith('.bdf') and f\"sub-{subject_id}\" in file:\n",
        "                bdf_file = os.path.join(session_path, file)\n",
        "                break\n",
        "\n",
        "        # Find the JSON metadata file (only for PD subjects)\n",
        "        json_file = None\n",
        "        if subject_id.startswith('pd') and json_path:\n",
        "            for file in os.listdir(json_path):\n",
        "                if file.endswith('.json'):\n",
        "                    json_file = os.path.join(json_path, file)\n",
        "                    break\n",
        "\n",
        "        # Store in dictionary\n",
        "        subject_data[subject_id] = {\n",
        "            \"bdf_file\": bdf_file,\n",
        "            \"json_file\": json_file if subject_id.startswith('pd') else None\n",
        "        }\n",
        "\n",
        "        # Print results\n",
        "        if bdf_file:\n",
        "            print(f\"‚úÖ Found EEG file: {bdf_file}\")\n",
        "        else:\n",
        "            print(f\"‚ùå No EEG file found for {subject_id}.\")\n",
        "\n",
        "        if json_file:\n",
        "            print(f\"‚úÖ Found JSON file: {json_file}\")\n",
        "        elif subject_id.startswith('pd'):\n",
        "            print(f\"‚ùå No JSON file found for {subject_id}.\")\n",
        "\n",
        "# Print final summary\n",
        "print(\"\\nüìù Summary of Collected Data:\")\n",
        "for subject, files in subject_data.items():\n",
        "    print(f\"Subject {subject}: EEG - {files['bdf_file']}, JSON - {files['json_file']}\")\n"
      ],
      "metadata": {
        "id": "qUgABcwjxycJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66133e24-1888-4754-f4aa-9bec595ce8dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing subject: hc33\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc33/ses-hc/eeg/sub-hc33_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd14\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd14/ses-off/eeg/sub-pd14_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd14/ses-off/beh/sub-pd14_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc21\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc21/ses-hc/eeg/sub-hc21_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc7\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc7/ses-hc/eeg/sub-hc7_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc10\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc10/ses-hc/eeg/sub-hc10_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd22\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd22/ses-off/eeg/sub-pd22_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd22/ses-off/beh/sub-pd22_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd28\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd28/ses-off/eeg/sub-pd28_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd28/ses-off/beh/sub-pd28_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc24\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc24/ses-hc/eeg/sub-hc24_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc18\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc18/ses-hc/eeg/sub-hc18_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd3\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd3/ses-off/eeg/sub-pd3_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd3/ses-off/beh/sub-pd3_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc25\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc25/ses-hc/eeg/sub-hc25_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd26\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd26/ses-off/eeg/sub-pd26_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd26/ses-off/beh/sub-pd26_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc8\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc8/ses-hc/eeg/sub-hc8_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd11\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd11/ses-off/eeg/sub-pd11_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd11/ses-off/beh/sub-pd11_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd13\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd13/ses-off/eeg/sub-pd13_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd13/ses-off/beh/sub-pd13_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc32\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc32/ses-hc/eeg/sub-hc32_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd17\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd17/ses-off/eeg/sub-pd17_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd17/ses-off/beh/sub-pd17_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd16\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd16/ses-off/eeg/sub-pd16_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd16/ses-off/beh/sub-pd16_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd19\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd19/ses-off/eeg/sub-pd19_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd19/ses-off/beh/sub-pd19_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd6\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd6/ses-off/eeg/sub-pd6_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd6/ses-off/beh/sub-pd6_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc2\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc2/ses-hc/eeg/sub-hc2_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc4\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc4/ses-hc/eeg/sub-hc4_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd23\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd23/ses-off/eeg/sub-pd23_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd23/ses-off/beh/sub-pd23_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc29\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc29/ses-hc/eeg/sub-hc29_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc20\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc20/ses-hc/eeg/sub-hc20_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd12\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd12/ses-off/eeg/sub-pd12_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd12/ses-off/beh/sub-pd12_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc1\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc1/ses-hc/eeg/sub-hc1_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd5\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd5/ses-off/eeg/sub-pd5_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd5/ses-off/beh/sub-pd5_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc30\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc30/ses-hc/eeg/sub-hc30_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc31\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc31/ses-hc/eeg/sub-hc31_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd9\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd9/ses-off/eeg/sub-pd9_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd9/ses-off/beh/sub-pd9_ses-off_task-rest_beh.json\n",
            "\n",
            "üìù Summary of Collected Data:\n",
            "Subject hc33: EEG - /content/ds002778/sub-hc33/ses-hc/eeg/sub-hc33_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd14: EEG - /content/ds002778/sub-pd14/ses-off/eeg/sub-pd14_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd14/ses-off/beh/sub-pd14_ses-off_task-rest_beh.json\n",
            "Subject hc21: EEG - /content/ds002778/sub-hc21/ses-hc/eeg/sub-hc21_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc7: EEG - /content/ds002778/sub-hc7/ses-hc/eeg/sub-hc7_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc10: EEG - /content/ds002778/sub-hc10/ses-hc/eeg/sub-hc10_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd22: EEG - /content/ds002778/sub-pd22/ses-off/eeg/sub-pd22_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd22/ses-off/beh/sub-pd22_ses-off_task-rest_beh.json\n",
            "Subject pd28: EEG - /content/ds002778/sub-pd28/ses-off/eeg/sub-pd28_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd28/ses-off/beh/sub-pd28_ses-off_task-rest_beh.json\n",
            "Subject hc24: EEG - /content/ds002778/sub-hc24/ses-hc/eeg/sub-hc24_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc18: EEG - /content/ds002778/sub-hc18/ses-hc/eeg/sub-hc18_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd3: EEG - /content/ds002778/sub-pd3/ses-off/eeg/sub-pd3_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd3/ses-off/beh/sub-pd3_ses-off_task-rest_beh.json\n",
            "Subject hc25: EEG - /content/ds002778/sub-hc25/ses-hc/eeg/sub-hc25_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd26: EEG - /content/ds002778/sub-pd26/ses-off/eeg/sub-pd26_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd26/ses-off/beh/sub-pd26_ses-off_task-rest_beh.json\n",
            "Subject hc8: EEG - /content/ds002778/sub-hc8/ses-hc/eeg/sub-hc8_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd11: EEG - /content/ds002778/sub-pd11/ses-off/eeg/sub-pd11_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd11/ses-off/beh/sub-pd11_ses-off_task-rest_beh.json\n",
            "Subject pd13: EEG - /content/ds002778/sub-pd13/ses-off/eeg/sub-pd13_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd13/ses-off/beh/sub-pd13_ses-off_task-rest_beh.json\n",
            "Subject hc32: EEG - /content/ds002778/sub-hc32/ses-hc/eeg/sub-hc32_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd17: EEG - /content/ds002778/sub-pd17/ses-off/eeg/sub-pd17_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd17/ses-off/beh/sub-pd17_ses-off_task-rest_beh.json\n",
            "Subject pd16: EEG - /content/ds002778/sub-pd16/ses-off/eeg/sub-pd16_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd16/ses-off/beh/sub-pd16_ses-off_task-rest_beh.json\n",
            "Subject pd19: EEG - /content/ds002778/sub-pd19/ses-off/eeg/sub-pd19_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd19/ses-off/beh/sub-pd19_ses-off_task-rest_beh.json\n",
            "Subject pd6: EEG - /content/ds002778/sub-pd6/ses-off/eeg/sub-pd6_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd6/ses-off/beh/sub-pd6_ses-off_task-rest_beh.json\n",
            "Subject hc2: EEG - /content/ds002778/sub-hc2/ses-hc/eeg/sub-hc2_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc4: EEG - /content/ds002778/sub-hc4/ses-hc/eeg/sub-hc4_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd23: EEG - /content/ds002778/sub-pd23/ses-off/eeg/sub-pd23_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd23/ses-off/beh/sub-pd23_ses-off_task-rest_beh.json\n",
            "Subject hc29: EEG - /content/ds002778/sub-hc29/ses-hc/eeg/sub-hc29_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc20: EEG - /content/ds002778/sub-hc20/ses-hc/eeg/sub-hc20_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd12: EEG - /content/ds002778/sub-pd12/ses-off/eeg/sub-pd12_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd12/ses-off/beh/sub-pd12_ses-off_task-rest_beh.json\n",
            "Subject hc1: EEG - /content/ds002778/sub-hc1/ses-hc/eeg/sub-hc1_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd5: EEG - /content/ds002778/sub-pd5/ses-off/eeg/sub-pd5_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd5/ses-off/beh/sub-pd5_ses-off_task-rest_beh.json\n",
            "Subject hc30: EEG - /content/ds002778/sub-hc30/ses-hc/eeg/sub-hc30_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc31: EEG - /content/ds002778/sub-hc31/ses-hc/eeg/sub-hc31_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd9: EEG - /content/ds002778/sub-pd9/ses-off/eeg/sub-pd9_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd9/ses-off/beh/sub-pd9_ses-off_task-rest_beh.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# raw_fname = target_dir\n",
        "\n",
        "# for subject_folder in os.listdir(raw_fname):\n",
        "#     if subject_folder.startswith('sub-'):\n",
        "#         subject_id = subject_folder.split('-')[1]\n",
        "#         print(f\"Processing subject: {subject_id}\")\n",
        "\n",
        "#         if subject_id.startswith('pd'):\n",
        "#             session_path = os.path.join(raw_fname, subject_folder, 'ses-off', 'eeg')\n",
        "#             session_type = 'ses-off'\n",
        "#         elif subject_id.startswith('hc'):\n",
        "#             session_path = os.path.join(raw_fname, subject_folder, 'ses-hc', 'eeg')\n",
        "#             session_type = 'ses-hc'\n",
        "#         else:\n",
        "#             print(f\"Unknown subject type for {subject_id}. Skipping.\")\n",
        "#             continue\n",
        "\n",
        "#         if not os.path.exists(session_path):\n",
        "#             print(f\"No '{session_type}/eeg' folder found for subject {subject_id}. Skipping.\")\n",
        "#             continue\n",
        "\n",
        "#         bdf_file = None\n",
        "#         for file in os.listdir(session_path):\n",
        "#             if file.endswith('.bdf') and f\"sub-{subject_id}\" in file:\n",
        "#                 bdf_file = os.path.join(session_path, file)\n",
        "#                 break\n",
        "\n",
        "#         if bdf_file:\n",
        "#             print(f\"Found EEG file for subject {subject_id} ({session_type}): {bdf_file}\")\n",
        "#             try:\n",
        "#                 with open(bdf_file, 'rb') as f:\n",
        "#                     header = f.read(256)\n",
        "#                     print(f\"Header for subject {subject_id}:\\n{header}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error reading file {bdf_file}: {e}\")\n",
        "#         else:\n",
        "#             print(f\"EEG .bdf file not found for subject {subject_id} in {session_type} session.\")\n"
      ],
      "metadata": {
        "id": "luHlXWSsy8Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correct running making changes to upper one(final)\n",
        "import os\n",
        "import openneuro\n",
        "import mne\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import welch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "subject_dirs = [d for d in os.listdir(target_dir) if d.startswith('sub-')]\n",
        "\n",
        "print(f\"Found {len(subject_dirs)} subjects in the dataset.\")\n",
        "\n",
        "features_list = []\n",
        "epoch_length_sec = 5\n",
        "\n",
        "for subject in subject_dirs:\n",
        "    print(f\"Processing subject: {subject}\")\n",
        "\n",
        "    if 'sub-pd' in subject:\n",
        "        raw_fname = os.path.join(target_dir, subject, 'ses-off', 'eeg', f'{subject}_ses-off_task-rest_eeg.bdf')\n",
        "    else:\n",
        "        raw_fname = os.path.join(target_dir, subject, 'ses-hc', 'eeg', f'{subject}_ses-hc_task-rest_eeg.bdf')\n",
        "\n",
        "    if not os.path.exists(raw_fname):\n",
        "        print(f\"EEG data file not found for {subject}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        raw = mne.io.read_raw_bdf(raw_fname, preload=True)\n",
        "        raw_filtered = raw.filter(l_freq=0.5, h_freq=50, fir_design='firwin', verbose=True)\n",
        "        montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "        raw_filtered.set_montage(montage, on_missing=\"ignore\")\n",
        "\n",
        "        ica = mne.preprocessing.ICA(n_components=20, random_state=42, max_iter=1000)\n",
        "        ica.fit(raw_filtered)\n",
        "        raw_cleaned = ica.apply(raw_filtered)\n",
        "\n",
        "        sfreq = raw.info['sfreq']\n",
        "        n_samples_per_epoch = int(epoch_length_sec * sfreq)\n",
        "        n_epochs = int(raw_filtered.n_times // n_samples_per_epoch)\n",
        "\n",
        "        events = np.array([[i * n_samples_per_epoch, 0, i] for i in range(n_epochs)])\n",
        "\n",
        "        event_id = {f\"epoch_{i}\": i for i in range(n_epochs)}\n",
        "\n",
        "        epochs = mne.Epochs(raw_filtered, events, event_id=event_id, tmin=0, tmax=epoch_length_sec, baseline=None, detrend=1, preload=True)\n",
        "\n",
        "        freq_bands = {\n",
        "            'delta': (1, 4),\n",
        "            'theta': (4, 8),\n",
        "            'alpha': (8, 12),\n",
        "            'beta': (12, 30),\n",
        "            'gamma': (30, 50)\n",
        "        }\n",
        "\n",
        "        def compute_band_power(epoch_data, sfreq, freq_bands):\n",
        "            power_features = {}\n",
        "            for band, (low, high) in freq_bands.items():\n",
        "                f, psd = welch(epoch_data, sfreq, nperseg=1024)\n",
        "                psd = psd[(f >= low) & (f <= high)]\n",
        "                power = np.sum(psd)\n",
        "                power_features[f'{band}_power'] = power\n",
        "            return power_features\n",
        "\n",
        "        for epoch_idx, epoch_data in enumerate(epochs.get_data()):\n",
        "            band_power = compute_band_power(epoch_data.mean(axis=0), raw.info['sfreq'], freq_bands)\n",
        "            band_power['subject'] = subject\n",
        "            band_power['epoch'] = epoch_idx\n",
        "            features_list.append(band_power)\n",
        "\n",
        "        print(f\"EEG data for {subject} loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data for subject {subject}: {e}\")\n",
        "\n",
        "print(f\"Total epochs processed: {len(features_list)}\")\n",
        "\n",
        "if features_list:\n",
        "    features_df = pd.DataFrame(features_list)\n",
        "    features_df.to_csv(\"eeg_features.csv\", index=False)\n",
        "    print(\"Feature extraction complete. Features saved to 'eeg_features.csv'.\")\n",
        "else:\n",
        "    print(\"No features extracted. The CSV will not be created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMm3TKPz0Kmp",
        "outputId": "ab16df2d-a744-467c-959c-8aef7b182b36"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 31 subjects in the dataset.\n",
            "Processing subject: sub-hc33\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc33/ses-hc/eeg/sub-hc33_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97279  =      0.000 ...   189.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "1 bad epochs dropped\n",
            "EEG data for sub-hc33 loaded successfully.\n",
            "Processing subject: sub-pd14\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd14/ses-off/eeg/sub-pd14_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 149503  =      0.000 ...   291.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "58 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 58 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd14 loaded successfully.\n",
            "Processing subject: sub-hc21\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc21/ses-hc/eeg/sub-hc21_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96767  =      0.000 ...   188.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc21 loaded successfully.\n",
            "Processing subject: sub-hc7\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc7/ses-hc/eeg/sub-hc7_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 98303  =      0.000 ...   191.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc7 loaded successfully.\n",
            "Processing subject: sub-hc10\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc10/ses-hc/eeg/sub-hc10_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 102911  =      0.000 ...   200.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc10 loaded successfully.\n",
            "Processing subject: sub-pd22\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd22/ses-off/eeg/sub-pd22_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96255  =      0.000 ...   187.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd22 loaded successfully.\n",
            "Processing subject: sub-pd28\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd28/ses-off/eeg/sub-pd28_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 105471  =      0.000 ...   205.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "41 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 41 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd28 loaded successfully.\n",
            "Processing subject: sub-hc24\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc24/ses-hc/eeg/sub-hc24_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 98303  =      0.000 ...   191.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc24 loaded successfully.\n",
            "Processing subject: sub-hc18\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc18/ses-hc/eeg/sub-hc18_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95231  =      0.000 ...   185.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.0s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc18 loaded successfully.\n",
            "Processing subject: sub-pd3\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd3/ses-off/eeg/sub-pd3_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 102399  =      0.000 ...   199.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.4s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "1 bad epochs dropped\n",
            "EEG data for sub-pd3 loaded successfully.\n",
            "Processing subject: sub-hc25\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc25/ses-hc/eeg/sub-hc25_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 103423  =      0.000 ...   201.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.0s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc25 loaded successfully.\n",
            "Processing subject: sub-pd26\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd26/ses-off/eeg/sub-pd26_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd26 loaded successfully.\n",
            "Processing subject: sub-hc8\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc8/ses-hc/eeg/sub-hc8_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc8 loaded successfully.\n",
            "Processing subject: sub-pd11\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd11/ses-off/eeg/sub-pd11_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95231  =      0.000 ...   185.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 49.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd11 loaded successfully.\n",
            "Processing subject: sub-pd13\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd13/ses-off/eeg/sub-pd13_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95231  =      0.000 ...   185.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.0s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd13 loaded successfully.\n",
            "Processing subject: sub-hc32\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc32/ses-hc/eeg/sub-hc32_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 100351  =      0.000 ...   195.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "39 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 39 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc32 loaded successfully.\n",
            "Processing subject: sub-pd17\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd17/ses-off/eeg/sub-pd17_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96767  =      0.000 ...   188.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.4s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd17 loaded successfully.\n",
            "Processing subject: sub-pd16\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd16/ses-off/eeg/sub-pd16_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96255  =      0.000 ...   187.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.9s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd16 loaded successfully.\n",
            "Processing subject: sub-pd19\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd19/ses-off/eeg/sub-pd19_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 94719  =      0.000 ...   184.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 2.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "1 bad epochs dropped\n",
            "EEG data for sub-pd19 loaded successfully.\n",
            "Processing subject: sub-pd6\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd6/ses-off/eeg/sub-pd6_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd6 loaded successfully.\n",
            "Processing subject: sub-hc2\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc2/ses-hc/eeg/sub-hc2_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 99327  =      0.000 ...   193.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc2 loaded successfully.\n",
            "Processing subject: sub-hc4\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc4/ses-hc/eeg/sub-hc4_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 92671  =      0.000 ...   180.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 56.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "36 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 36 events and 2561 original time points ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py:127: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 bad epochs dropped\n",
            "EEG data for sub-hc4 loaded successfully.\n",
            "Processing subject: sub-pd23\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd23/ses-off/eeg/sub-pd23_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 104447  =      0.000 ...   203.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd23 loaded successfully.\n",
            "Processing subject: sub-hc29\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc29/ses-hc/eeg/sub-hc29_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 101887  =      0.000 ...   198.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "39 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 39 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc29 loaded successfully.\n",
            "Processing subject: sub-hc20\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc20/ses-hc/eeg/sub-hc20_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 94207  =      0.000 ...   183.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "36 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 36 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc20 loaded successfully.\n",
            "Processing subject: sub-pd12\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd12/ses-off/eeg/sub-pd12_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 105983  =      0.000 ...   206.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.0s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "41 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 41 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd12 loaded successfully.\n",
            "Processing subject: sub-hc1\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc1/ses-hc/eeg/sub-hc1_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 98303  =      0.000 ...   191.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.2s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc1 loaded successfully.\n",
            "Processing subject: sub-pd5\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd5/ses-off/eeg/sub-pd5_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 100863  =      0.000 ...   196.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.9s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "39 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 39 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd5 loaded successfully.\n",
            "Processing subject: sub-hc30\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc30/ses-hc/eeg/sub-hc30_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96767  =      0.000 ...   188.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 1.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc30 loaded successfully.\n",
            "Processing subject: sub-hc31\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc31/ses-hc/eeg/sub-hc31_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95743  =      0.000 ...   186.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc31 loaded successfully.\n",
            "Processing subject: sub-pd9\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd9/ses-off/eeg/sub-pd9_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd9 loaded successfully.\n",
            "Total epochs processed: 1198\n",
            "Feature extraction complete. Features saved to 'eeg_features.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Path to dataset\n",
        "target_dir = '/content/ds002778'\n",
        "\n",
        "# Store extracted metadata\n",
        "metadata_list = []\n",
        "\n",
        "# Get all subject folders\n",
        "subject_dirs = [d for d in os.listdir(target_dir) if d.startswith('sub-pd')]\n",
        "\n",
        "print(f\"Found {len(subject_dirs)} Parkinson's subjects with possible JSON metadata.\")\n",
        "\n",
        "for subject in subject_dirs:\n",
        "    print(f\"Processing JSON for {subject}...\")\n",
        "\n",
        "    json_path = os.path.join(target_dir, subject, 'ses-off', 'beh')\n",
        "\n",
        "    if not os.path.exists(json_path):\n",
        "        print(f\"No JSON folder found for {subject}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    # Find the JSON file in the folder\n",
        "    json_file = None\n",
        "    for file in os.listdir(json_path):\n",
        "        if file.endswith('.json'):\n",
        "            json_file = os.path.join(json_path, file)\n",
        "            break\n",
        "\n",
        "    if not json_file:\n",
        "        print(f\"No JSON file found for {subject}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        # Load JSON data\n",
        "        with open(json_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # Extract relevant metadata (modify keys as needed)\n",
        "        metadata_entry = {\n",
        "            \"subject\": subject,\n",
        "            \"Lev_Dose_mg\": data[\"meds\"][\"Lev\"][\"Dose (mg)\"] if \"Lev\" in data[\"meds\"] else None,\n",
        "            \"Lev_hours_since_meds\": data[\"meds\"][\"Lev\"][\"hours since meds\"] if \"Lev\" in data[\"meds\"] else None,\n",
        "            \"Lev_times_per_day\": data[\"meds\"][\"Lev\"][\"times/day\"] if \"Lev\" in data[\"meds\"] else None,\n",
        "            \"Ras_Dose_mg\": data[\"meds\"][\"Ras\"][\"Dose (mg)\"] if \"Ras\" in data[\"meds\"] else None,\n",
        "            \"Ras_hours_since_meds\": data[\"meds\"][\"Ras\"][\"hours since meds\"] if \"Ras\" in data[\"meds\"] else None,\n",
        "            \"Ras_times_per_day\": data[\"meds\"][\"Ras\"][\"times/day\"] if \"Ras\" in data[\"meds\"] else None,\n",
        "            \"Beck_Score\": data[\"questionairres\"][\"Beck\"] if \"Beck\" in data[\"questionairres\"] else None,\n",
        "            \"Bradykinesia_UPDRS\": data[\"questionairres\"][\"Brady kinesia UPDRS\"] if \"Brady kinesia UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"H_Y_Stage\": data[\"questionairres\"][\"H&Y\"] if \"H&Y\" in data[\"questionairres\"] else None,\n",
        "            \"Left_UPDRS\": data[\"questionairres\"][\"Left UPDRS\"] if \"Left UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Rest_Tremor_UPDRS\": data[\"questionairres\"][\"Rest Tremor UPDRS\"] if \"Rest Tremor UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Right_UPDRS\": data[\"questionairres\"][\"Right UPDRS\"] if \"Right UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Rigidity_UPDRS\": data[\"questionairres\"][\"Rigidity UPDRS\"] if \"Rigidity UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Total_UPDRS\": data[\"questionairres\"][\"Total UPDRS\"] if \"Total UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"UPDRS_18_26\": data[\"questionairres\"][\"UPDRS 18-26\"] if \"UPDRS 18-26\" in data[\"questionairres\"] else None\n",
        "        }\n",
        "\n",
        "        metadata_list.append(metadata_entry)\n",
        "        print(f\" JSON processed for {subject}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing JSON for {subject}: {e}\")\n",
        "\n",
        "# Convert metadata to DataFrame\n",
        "if metadata_list:\n",
        "    metadata_df = pd.DataFrame(metadata_list)\n",
        "    metadata_df.to_csv(\"json_metadata.csv\", index=False)\n",
        "    print(\" JSON metadata saved to 'json_metadata.csv'.\")\n",
        "else:\n",
        "    print(\" No JSON data extracted.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DZrGsaon9S8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a22b5fc6-1f7f-4851-f0a4-92a8c6f07aa3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15 Parkinson's subjects with possible JSON metadata.\n",
            "Processing JSON for sub-pd14...\n",
            " JSON processed for sub-pd14.\n",
            "Processing JSON for sub-pd22...\n",
            " JSON processed for sub-pd22.\n",
            "Processing JSON for sub-pd28...\n",
            " JSON processed for sub-pd28.\n",
            "Processing JSON for sub-pd3...\n",
            " JSON processed for sub-pd3.\n",
            "Processing JSON for sub-pd26...\n",
            " JSON processed for sub-pd26.\n",
            "Processing JSON for sub-pd11...\n",
            " JSON processed for sub-pd11.\n",
            "Processing JSON for sub-pd13...\n",
            " JSON processed for sub-pd13.\n",
            "Processing JSON for sub-pd17...\n",
            " JSON processed for sub-pd17.\n",
            "Processing JSON for sub-pd16...\n",
            " JSON processed for sub-pd16.\n",
            "Processing JSON for sub-pd19...\n",
            " JSON processed for sub-pd19.\n",
            "Processing JSON for sub-pd6...\n",
            " JSON processed for sub-pd6.\n",
            "Processing JSON for sub-pd23...\n",
            " JSON processed for sub-pd23.\n",
            "Processing JSON for sub-pd12...\n",
            " JSON processed for sub-pd12.\n",
            "Processing JSON for sub-pd5...\n",
            " JSON processed for sub-pd5.\n",
            "Processing JSON for sub-pd9...\n",
            " JSON processed for sub-pd9.\n",
            " JSON metadata saved to 'json_metadata.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load EEG features\n",
        "eeg_features_df = pd.read_csv(\"eeg_features.csv\")\n",
        "print(f\"EEG features loaded: {eeg_features_df.shape}\")\n",
        "\n",
        "# Load JSON metadata (only PD subjects have this)\n",
        "json_metadata_df = pd.read_csv(\"json_metadata.csv\")\n",
        "print(f\"JSON metadata loaded: {json_metadata_df.shape}\")\n",
        "\n",
        "# Merge with left join to retain all EEG subjects\n",
        "merged_df = pd.merge(eeg_features_df, json_metadata_df, on=\"subject\", how=\"left\")\n",
        "\n",
        "# Identify HC subjects (those with missing H&Y values)\n",
        "merged_df[\"is_hc\"] = merged_df[\"H_Y_Stage\"].isna()\n",
        "\n",
        "# Define risk percentage function\n",
        "def calculate_risk_percentage(hy_stage, is_hc):\n",
        "    if is_hc:\n",
        "        return 0  # HC subjects have 0% risk\n",
        "    elif hy_stage <= 1.0:\n",
        "        return 20\n",
        "    elif hy_stage >= 3.0:\n",
        "        return 100\n",
        "    else:\n",
        "        return 20 + (hy_stage - 1.0) * ((100 - 20) / (3.0 - 1.0))\n",
        "\n",
        "# Apply risk calculation\n",
        "merged_df[\"risk_percentage\"] = merged_df.apply(lambda row: calculate_risk_percentage(row[\"H_Y_Stage\"], row[\"is_hc\"]), axis=1)\n",
        "\n",
        "# Save the updated dataset\n",
        "merged_df.to_csv(\"merged_dataset_with_risk.csv\", index=False)\n",
        "print(f\" Merged dataset saved as 'merged_dataset_with_risk.csv' with shape: {merged_df.shape}\")\n"
      ],
      "metadata": {
        "id": "GpE-3lIQoj83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4056ee76-8338-4cf0-8200-75b3d4a23181"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG features loaded: (1198, 7)\n",
            "JSON metadata loaded: (15, 16)\n",
            " Merged dataset saved as 'merged_dataset_with_risk.csv' with shape: (1198, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "Ynv-dHqN9ZTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf6e038-ecee-4ecb-b5b7-4274f0e72d5f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load EEG dataset (Modify the filename accordingly)\n",
        "df = pd.read_csv(\"merged_dataset_with_risk.csv\")  # Replace with actual EEG dataset filename\n",
        "\n",
        "# Select only EEG features (Modify if necessary)\n",
        "eeg_features = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "\n",
        "# Ensure label column exists (Modify according to dataset structure)\n",
        "if 'risk_percentage' not in df.columns:\n",
        "    raise ValueError(\"The dataset must contain a 'risk_percentage' column!\")\n",
        "\n",
        "# Extract features and target variable\n",
        "X = df[eeg_features]\n",
        "y = df['risk_percentage']  # Target variable (0-100 risk percentage)\n",
        "\n",
        "# Split data into 80% train and 20% test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)\n",
        "\n",
        "# Combine into train and test dataframes\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "# Save to CSV files\n",
        "train_df.to_csv(\"train_set.csv\", index=False)\n",
        "test_df.to_csv(\"test_set.csv\", index=False)\n",
        "\n",
        "print(\"Train and test datasets created successfully!\")\n"
      ],
      "metadata": {
        "id": "czwwfEY8-BfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72fccebe-3607-47e7-b1f9-3e52a9a5367b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and test datasets created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.utils import shuffle\n",
        "# from keras_tuner.tuners import RandomSearch\n",
        "# import random\n",
        "\n",
        "# # Set random seeds for reproducibility\n",
        "# np.random.seed(42)\n",
        "# random.seed(42)\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# # Load EEG datasets\n",
        "# train_df = pd.read_csv(\"train_set.csv\")\n",
        "# test_df = pd.read_csv(\"test_set.csv\")\n",
        "\n",
        "# # Feature selection - Only EEG features\n",
        "# eeg_features = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "\n",
        "# # Extract features and labels\n",
        "# X_train = train_df[eeg_features].values\n",
        "# X_test = test_df[eeg_features].values\n",
        "# y_train = train_df['risk_percentage'].values  # Change label to risk percentage\n",
        "# y_test = test_df['risk_percentage'].values\n",
        "\n",
        "# # Normalize data\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Reshape for CNN input (1D Conv)\n",
        "# X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "# X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# # Define CNN model using Keras Tuner\n",
        "# def build_cnn_model(hp):\n",
        "#     model = Sequential()\n",
        "\n",
        "#     model.add(Conv1D(\n",
        "#         filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
        "#         kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2),\n",
        "#         activation='relu',\n",
        "#         padding='same',\n",
        "#         input_shape=(X_train_scaled.shape[1], 1)\n",
        "#     ))\n",
        "#     model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#     model.add(Flatten())\n",
        "\n",
        "#     for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "#         model.add(Dense(\n",
        "#             units=hp.Int(f'units_dense_{i}', min_value=32, max_value=128, step=32),\n",
        "#             activation='relu'\n",
        "#         ))\n",
        "#         model.add(Dropout(hp.Float(f'dropout_dense_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "#     # Output layer for risk percentage (0-100)\n",
        "#     model.add(Dense(1, activation='sigmoid'))  # Sigmoid to scale output between 0 and 1\n",
        "\n",
        "#     optimizer = Adam(\n",
        "#         learning_rate=hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4])\n",
        "#     )\n",
        "#     model.compile(\n",
        "#         optimizer=optimizer,\n",
        "#         loss='mse',  # Mean Squared Error for continuous values\n",
        "#         metrics=['mae']\n",
        "#     )\n",
        "\n",
        "#     return model\n",
        "\n",
        "# # Hyperparameter tuning using RandomSearch\n",
        "# tuner = RandomSearch(\n",
        "#     build_cnn_model,\n",
        "#     objective='val_mae',\n",
        "#     max_trials=10,\n",
        "#     executions_per_trial=1,\n",
        "#     directory='hyperparam_tuning',\n",
        "#     project_name='eeg_risk_prediction_cnn'\n",
        "# )\n",
        "\n",
        "# # Perform tuning\n",
        "# tuner.search(\n",
        "#     X_train_scaled, y_train,\n",
        "#     epochs=50,\n",
        "#     validation_split=0.2,\n",
        "#     batch_size=32,\n",
        "#     callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        "# )\n",
        "\n",
        "# # Get the best hyperparameters\n",
        "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# # Build the best model\n",
        "# best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# # Train the best model\n",
        "# history = best_model.fit(\n",
        "#     X_train_scaled, y_train,\n",
        "#     epochs=100,\n",
        "#     batch_size=32,\n",
        "#     validation_split=0.2,\n",
        "#     callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# # Evaluate on test data\n",
        "# test_loss, test_mae = best_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "# print(f\"\\nTest MAE: {test_mae:.4f}\")\n",
        "\n",
        "# # Predict risk percentage\n",
        "# predictions = best_model.predict(X_test_scaled) * 100  # Convert to percentage\n",
        "\n",
        "# # Save predictions\n",
        "# test_df['predicted_risk_percentage'] = predictions.flatten()\n",
        "# test_df.to_csv(\"eeg_test_predictions.csv\", index=False)\n",
        "\n",
        "# print(\"Predictions saved to 'eeg_test_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX4IMZr4NjFy",
        "outputId": "127a2efe-ec97-489b-92cf-48c55f30c0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 19s]\n",
            "val_mae: 39.79166793823242\n",
            "\n",
            "Best val_mae So Far: 39.789974212646484\n",
            "Total elapsed time: 00h 04m 07s\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3228.9380 - mae: 39.5166 - val_loss: 3319.8665 - val_mae: 39.7931\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3219.2703 - mae: 39.5170 - val_loss: 3302.7991 - val_mae: 39.7931\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3202.1057 - mae: 39.5153 - val_loss: 3290.7244 - val_mae: 39.7926\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3193.7192 - mae: 39.5099 - val_loss: 3288.8289 - val_mae: 39.7924\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.9937 - mae: 39.5071 - val_loss: 3288.4678 - val_mae: 39.7922\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.6953 - mae: 39.5073 - val_loss: 3288.3193 - val_mae: 39.7921\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.6250 - mae: 39.5075 - val_loss: 3288.2285 - val_mae: 39.7919\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.5144 - mae: 39.5075 - val_loss: 3288.1768 - val_mae: 39.7919\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.4299 - mae: 39.5071 - val_loss: 3288.1482 - val_mae: 39.7918\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3191.4263 - mae: 39.5075 - val_loss: 3288.1301 - val_mae: 39.7918\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3752 - mae: 39.5070 - val_loss: 3288.1182 - val_mae: 39.7917\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.4043 - mae: 39.5077 - val_loss: 3288.1072 - val_mae: 39.7917\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3862 - mae: 39.5077 - val_loss: 3288.1003 - val_mae: 39.7917\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3635 - mae: 39.5075 - val_loss: 3288.0967 - val_mae: 39.7917\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3650 - mae: 39.5076 - val_loss: 3288.0930 - val_mae: 39.7917\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3826 - mae: 39.5077 - val_loss: 3288.0906 - val_mae: 39.7917\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3623 - mae: 39.5077 - val_loss: 3288.0891 - val_mae: 39.7917\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3352 - mae: 39.5074 - val_loss: 3288.0879 - val_mae: 39.7917\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3525 - mae: 39.5076 - val_loss: 3288.0869 - val_mae: 39.7917\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3330 - mae: 39.5075 - val_loss: 3288.0867 - val_mae: 39.7917\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3350 - mae: 39.5075 - val_loss: 3288.0857 - val_mae: 39.7917\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3416 - mae: 39.5076 - val_loss: 3288.0857 - val_mae: 39.7917\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3191.3374 - mae: 39.5075 - val_loss: 3288.0850 - val_mae: 39.7917\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3550 - mae: 39.5076 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3274 - mae: 39.5075 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3281 - mae: 39.5075 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3318 - mae: 39.5075 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3284 - mae: 39.5075 - val_loss: 3288.0840 - val_mae: 39.7917\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3315 - mae: 39.5075 - val_loss: 3288.0840 - val_mae: 39.7917\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3284 - mae: 39.5075 - val_loss: 3288.0840 - val_mae: 39.7917\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3328 - mae: 39.5075 - val_loss: 3288.0837 - val_mae: 39.7917\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3191.3333 - mae: 39.5075 - val_loss: 3288.0837 - val_mae: 39.7917\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3267 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3191.3274 - mae: 39.5074 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3191.3245 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3191.3264 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3191.3252 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3240 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3247 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3191.3240 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3237 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3191.3235 - mae: 39.5074 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3191.3252 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "\n",
            "Test MAE: 40.3000\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 78ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c2dd4f83e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Predictions saved to 'eeg_test_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, Attention, Multiply\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Load Data\n",
        "# train_df = pd.read_csv(\"train_set.csv\")\n",
        "# test_df = pd.read_csv(\"test_set.csv\")\n",
        "\n",
        "# # Feature Engineering\n",
        "# def engineer_features(df):\n",
        "#     feature_columns = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "#     df['theta_alpha_ratio'] = df['theta_power'] / df['alpha_power']\n",
        "#     df['alpha_beta_ratio'] = df['alpha_power'] / df['beta_power']\n",
        "#     df['delta_theta_ratio'] = df['delta_power'] / df['theta_power']\n",
        "#     df['beta_gamma_ratio'] = df['beta_power'] / df['gamma_power']\n",
        "\n",
        "#     total_power = df[feature_columns].sum(axis=1)\n",
        "#     for band in feature_columns:\n",
        "#         df[f'relative_{band}'] = df[band] / total_power\n",
        "\n",
        "#     df['alpha_theta_diff'] = df['alpha_power'] - df['theta_power']\n",
        "#     df['beta_alpha_diff'] = df['beta_power'] - df['alpha_power']\n",
        "#     df['mean_power'] = df[feature_columns].mean(axis=1)\n",
        "#     df['std_power'] = df[feature_columns].std(axis=1)\n",
        "\n",
        "#     return df\n",
        "\n",
        "# train_df = engineer_features(train_df)\n",
        "# test_df = engineer_features(test_df)\n",
        "\n",
        "# # Feature Selection\n",
        "# feature_columns = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power',\n",
        "#                    'theta_alpha_ratio', 'alpha_beta_ratio', 'delta_theta_ratio', 'beta_gamma_ratio',\n",
        "#                    'relative_delta_power', 'relative_theta_power', 'relative_alpha_power',\n",
        "#                    'relative_beta_power', 'relative_gamma_power',\n",
        "#                    'alpha_theta_diff', 'beta_alpha_diff', 'mean_power', 'std_power']\n",
        "\n",
        "# X_train = train_df[feature_columns].values\n",
        "# X_test = test_df[feature_columns].values\n",
        "# y_train = train_df['risk_percentage'].values / 100  # Normalize [0,1]\n",
        "# y_test = test_df['risk_percentage'].values / 100\n",
        "\n",
        "# # Scaling Features\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Reshape for LSTM (samples, timesteps=1, features)\n",
        "# X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "# X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# # Build LSTM Model with Attention\n",
        "# def build_lstm_model():\n",
        "#     input_layer = Input(shape=(1, X_train_scaled.shape[2]))\n",
        "\n",
        "#     # BiLSTM Layer\n",
        "#     lstm_out = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(input_layer)\n",
        "\n",
        "#     # Attention Mechanism\n",
        "#     query = Dense(256, activation=\"tanh\")(lstm_out)  # Ensure query matches LSTM output\n",
        "#     attention = Attention()([query, lstm_out])\n",
        "#     context_vector = Multiply()([attention, lstm_out])\n",
        "\n",
        "#     # Second BiLSTM Layer\n",
        "#     lstm_out2 = Bidirectional(LSTM(64, return_sequences=False, dropout=0.2))(context_vector)\n",
        "\n",
        "#     # Fully Connected Layers\n",
        "#     dense_out = Dense(64, activation='relu')(lstm_out2)\n",
        "#     dropout_out = Dropout(0.3)(dense_out)\n",
        "#     output_layer = Dense(1, activation='sigmoid')(dropout_out)  # Output risk percentage\n",
        "\n",
        "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
        "#     model.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
        "\n",
        "#     return model\n",
        "\n",
        "# # Initialize and Train Model\n",
        "# model = build_lstm_model()\n",
        "\n",
        "# history = model.fit(\n",
        "#     X_train_scaled, y_train,\n",
        "#     epochs=100,\n",
        "#     batch_size=32,\n",
        "#     validation_split=0.2,\n",
        "#     callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# # Evaluate Model\n",
        "# test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "# print(f\"\\nTest MAE: {test_mae:.4f} (Lower is better)\")\n",
        "\n",
        "# # Make Predictions\n",
        "# y_pred = model.predict(X_test_scaled) * 100  # Convert back to percentage scale\n",
        "\n",
        "# # Save Model & Predictions\n",
        "# model.save(\"eeg_risk_prediction_lstm.h5\")\n",
        "\n",
        "# predictions_df = pd.DataFrame({\"Actual\": y_test * 100, \"Predicted\": y_pred.flatten()})\n",
        "# predictions_df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "# print(\"Model training complete. Predictions saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOHmL-riOTaK",
        "outputId": "8b7fac85-45e0-46f2-c3c2-b9c2a7df1762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3858 - mae: 0.3858"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 104ms/step - loss: 0.3862 - mae: 0.3862 - val_loss: 0.3975 - val_mae: 0.3975\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.3857 - mae: 0.3857 - val_loss: 0.3967 - val_mae: 0.3967\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.3850 - mae: 0.3850 - val_loss: 0.3943 - val_mae: 0.3943\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3820 - mae: 0.3820 - val_loss: 0.3854 - val_mae: 0.3854\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - loss: 0.3700 - mae: 0.3700 - val_loss: 0.3621 - val_mae: 0.3621\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 57ms/step - loss: 0.3541 - mae: 0.3541 - val_loss: 0.3470 - val_mae: 0.3470\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - loss: 0.3399 - mae: 0.3399 - val_loss: 0.3385 - val_mae: 0.3385\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - loss: 0.3303 - mae: 0.3303 - val_loss: 0.3347 - val_mae: 0.3347\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.3269 - mae: 0.3269 - val_loss: 0.3277 - val_mae: 0.3277\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.3242 - mae: 0.3242 - val_loss: 0.3260 - val_mae: 0.3260\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.3186 - mae: 0.3186 - val_loss: 0.3188 - val_mae: 0.3188\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.3218 - mae: 0.3218 - val_loss: 0.3167 - val_mae: 0.3167\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3180 - mae: 0.3180 - val_loss: 0.3172 - val_mae: 0.3172\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3213 - mae: 0.3213 - val_loss: 0.3139 - val_mae: 0.3139\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.3116 - mae: 0.3116 - val_loss: 0.3124 - val_mae: 0.3124\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3184 - mae: 0.3184 - val_loss: 0.3151 - val_mae: 0.3151\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3176 - mae: 0.3176 - val_loss: 0.3112 - val_mae: 0.3112\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3171 - mae: 0.3171 - val_loss: 0.3120 - val_mae: 0.3120\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3082 - mae: 0.3082 - val_loss: 0.3200 - val_mae: 0.3200\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.3043 - mae: 0.3043 - val_loss: 0.3122 - val_mae: 0.3122\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.3058 - mae: 0.3058 - val_loss: 0.3079 - val_mae: 0.3079\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.3030 - mae: 0.3030 - val_loss: 0.3068 - val_mae: 0.3068\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3027 - mae: 0.3027 - val_loss: 0.3129 - val_mae: 0.3129\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3072 - mae: 0.3072 - val_loss: 0.3077 - val_mae: 0.3077\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3024 - mae: 0.3024 - val_loss: 0.3066 - val_mae: 0.3066\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3026 - mae: 0.3026 - val_loss: 0.3160 - val_mae: 0.3160\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.3002 - mae: 0.3002 - val_loss: 0.3089 - val_mae: 0.3089\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.2863 - mae: 0.2863 - val_loss: 0.3081 - val_mae: 0.3081\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.2995 - mae: 0.2995 - val_loss: 0.3037 - val_mae: 0.3037\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.3046 - mae: 0.3046 - val_loss: 0.3069 - val_mae: 0.3069\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.3085 - mae: 0.3085 - val_loss: 0.3107 - val_mae: 0.3107\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.2972 - mae: 0.2972 - val_loss: 0.3113 - val_mae: 0.3113\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.3082 - mae: 0.3082 - val_loss: 0.3013 - val_mae: 0.3013\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.3130 - mae: 0.3130 - val_loss: 0.3022 - val_mae: 0.3022\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.2984 - mae: 0.2984 - val_loss: 0.3029 - val_mae: 0.3029\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.2986 - mae: 0.2986 - val_loss: 0.2996 - val_mae: 0.2996\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.2973 - mae: 0.2973 - val_loss: 0.3013 - val_mae: 0.3013\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.2936 - mae: 0.2936 - val_loss: 0.3052 - val_mae: 0.3052\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.2909 - mae: 0.2909 - val_loss: 0.3037 - val_mae: 0.3037\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.2991 - mae: 0.2991 - val_loss: 0.3014 - val_mae: 0.3014\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.2878 - mae: 0.2878 - val_loss: 0.3080 - val_mae: 0.3080\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.2888 - mae: 0.2888 - val_loss: 0.3156 - val_mae: 0.3156\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.2883 - mae: 0.2883 - val_loss: 0.3084 - val_mae: 0.3084\n",
            "Epoch 44/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.2920 - mae: 0.2920 - val_loss: 0.3090 - val_mae: 0.3090\n",
            "Epoch 45/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.3060 - mae: 0.3060 - val_loss: 0.3043 - val_mae: 0.3043\n",
            "Epoch 46/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.2952 - mae: 0.2952 - val_loss: 0.3065 - val_mae: 0.3065\n",
            "\n",
            "Test MAE: 0.2870 (Lower is better)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 138ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete. Predictions saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, LayerNormalization, Multiply, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Data\n",
        "train_df = pd.read_csv(\"train_set.csv\")\n",
        "test_df = pd.read_csv(\"test_set.csv\")\n",
        "\n",
        "# Feature Engineering\n",
        "def engineer_features(df):\n",
        "    feature_columns = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "    df['theta_alpha_ratio'] = df['theta_power'] / df['alpha_power']\n",
        "    df['alpha_beta_ratio'] = df['alpha_power'] / df['beta_power']\n",
        "    df['delta_theta_ratio'] = df['delta_power'] / df['theta_power']\n",
        "    df['beta_gamma_ratio'] = df['beta_power'] / df['gamma_power']\n",
        "\n",
        "    total_power = df[feature_columns].sum(axis=1)\n",
        "    for band in feature_columns:\n",
        "        df[f'relative_{band}'] = df[band] / total_power\n",
        "\n",
        "    df['alpha_theta_diff'] = df['alpha_power'] - df['theta_power']\n",
        "    df['beta_alpha_diff'] = df['beta_power'] - df['alpha_power']\n",
        "    df['mean_power'] = df[feature_columns].mean(axis=1)\n",
        "    df['std_power'] = df[feature_columns].std(axis=1)\n",
        "    df['power_skewness'] = df[feature_columns].skew(axis=1)\n",
        "    df['power_kurtosis'] = df[feature_columns].kurtosis(axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = engineer_features(train_df)\n",
        "test_df = engineer_features(test_df)\n",
        "\n",
        "# Feature Selection\n",
        "feature_columns = train_df.columns.difference(['risk_percentage'])\n",
        "X_train = train_df[feature_columns].values\n",
        "X_test = test_df[feature_columns].values\n",
        "y_train = train_df['risk_percentage'].values / 100  # Normalize [0,1]\n",
        "y_test = test_df['risk_percentage'].values / 100\n",
        "\n",
        "# Scaling Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Custom Scaled Dot-Product Attention Layer\n",
        "class ScaledDotProductAttentionLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        query, key, value = inputs\n",
        "        scores = tf.matmul(query, key, transpose_b=True) / tf.math.sqrt(tf.cast(tf.shape(key)[-1], tf.float32))\n",
        "        weights = tf.nn.softmax(scores, axis=-1)\n",
        "        return tf.matmul(weights, value)\n",
        "\n",
        "# Build Optimized LSTM Model\n",
        "def build_lstm_model():\n",
        "    input_layer = Input(shape=(1, X_train_scaled.shape[2]))\n",
        "\n",
        "    # BiLSTM Layer\n",
        "    lstm_out = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(input_layer)\n",
        "\n",
        "    # Ensure Query, Key, and Value match LSTM output shape\n",
        "    query = Dense(128)(lstm_out)  # Changed Dense units to 128\n",
        "    key = Dense(128)(lstm_out)  # Changed Dense units to 128\n",
        "    value = Dense(128)(lstm_out)  # Changed Dense units to 128\n",
        "    attention_output = ScaledDotProductAttentionLayer()([query, key, value])\n",
        "\n",
        "    # Align dimensions before multiplication\n",
        "    # context_vector = Multiply()([attention_output, lstm_out]) # This line produced the error\n",
        "    # Correcting the shape of attention output:\n",
        "    attention_output_repeated = tf.repeat(attention_output, repeats=2, axis=2)\n",
        "    context_vector = Multiply()([attention_output_repeated, lstm_out])\n",
        "\n",
        "    # Second BiLSTM Layer\n",
        "    lstm_out2 = Bidirectional(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3))(context_vector)\n",
        "\n",
        "    # Normalization & Dense Layers\n",
        "    norm_out = LayerNormalization()(lstm_out2)\n",
        "    dense_out = Dense(64, activation='relu')(norm_out)\n",
        "    dropout_out = Dropout(0.4)(dense_out)\n",
        "    output_layer = Dense(1, activation='sigmoid')(dropout_out)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='huber_loss', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train Model\n",
        "model = build_lstm_model()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"\\nTest MAE: {test_mae:.4f} (Lower is better)\")\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test_scaled) * 100\n",
        "\n",
        "# Save Model & Predictions\n",
        "model.save(\"optimized_eeg_lstm.h5\")\n",
        "predictions_df = pd.DataFrame({\"Actual\": y_test * 100, \"Predicted\": y_pred.flatten()})\n",
        "predictions_df.to_csv(\"optimized_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Optimized model training complete. Predictions saved.\")\n"
      ],
      "metadata": {
        "id": "f1Jc3qY1-CBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "outputId": "ba311ec2-b30a-41e1-b8ef-0e7ff6ed9a28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-69185dc6bb08>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m history = model.fit(\n",
            "\u001b[0;32m<ipython-input-14-69185dc6bb08>\u001b[0m in \u001b[0;36mbuild_lstm_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# context_vector = Multiply()([attention_output, lstm_out]) # This line produced the error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Correcting the shape of attention output:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mattention_output_repeated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mcontext_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattention_output_repeated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_out\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/keras_tensor.py\u001b[0m in \u001b[0;36m__tf_tensor__\u001b[0;34m(self, dtype, name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__tf_tensor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;34m\"A KerasTensor cannot be used as input to a TensorFlow function. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;34m\"A KerasTensor is a symbolic placeholder for a shape and dtype, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjrQwNG4pYw2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}