{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzqC0cV4vDL5xIpk/caDre",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "449de3f680e24cadaddd251413ff5e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_820ca87aacad464fad58e856d00b206c",
              "IPY_MODEL_042c37871029455ba6520bd746cd81e1",
              "IPY_MODEL_bdff0c8c4695403ea205babf293c8fb9"
            ],
            "layout": "IPY_MODEL_b09c81b8112947ee81496f6999034d45"
          }
        },
        "820ca87aacad464fad58e856d00b206c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821a6469654d4984a8d808b6048cf3bf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_79223bdab2b54e4090408e956803b42b",
            "value": "üìÅ‚ÄáTraversing‚Äádirectories‚Äáfor‚Äáds002778‚Äá:‚Äá"
          }
        },
        "042c37871029455ba6520bd746cd81e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73f11997d68c4828acf63c299760dc31",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7167cda1fc6e4089a79e7d2282370a0b",
            "value": 1
          }
        },
        "bdff0c8c4695403ea205babf293c8fb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70929768f257417ab630df139b6ccd0f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_011c2cc50d384de0ad7a0cdb28fbd66f",
            "value": "‚Äá328/?‚Äá[00:52&lt;00:00,‚Äá‚Äá1.02s/‚Äáentities]"
          }
        },
        "b09c81b8112947ee81496f6999034d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821a6469654d4984a8d808b6048cf3bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79223bdab2b54e4090408e956803b42b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73f11997d68c4828acf63c299760dc31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7167cda1fc6e4089a79e7d2282370a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70929768f257417ab630df139b6ccd0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011c2cc50d384de0ad7a0cdb28fbd66f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vathsal14/NOVO-NEUROTECH/blob/main/newparkinsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests\n",
        "# Installs the 'requests' library, which is used for making HTTP requests in Python. It simplifies interacting with web services and APIs.\n",
        "# version: requests-2.32.3\n",
        "!pip install mne\n",
        "# Installs the 'mne' library, which is a powerful tool for processing, analyzing, and visualizing EEG, MEG, and other neurophysiological data.\n",
        "# version: mne-1.9.0\n",
        "!pip install pyedflib\n",
        "# Installs the 'pyedflib' library, which allows reading and writing of EDF (European Data Format) and BDF (Biosemi Data Format) files, commonly used in EEG data storage.\n",
        "# version: pyedflib-0.1.38\n",
        "!pip install openneuro-py\n",
        "# Installs the 'openneuro-py' library, a Python client for accessing and downloading datasets from OpenNeuro, a platform for neuroimaging data sharing.\n",
        "# aiofiles-24.1.0 graphql-core-3.2.5 openneuro-py-2024.2.0 sgqlc-16.4\n",
        "!pip install PyWavelets\n",
        "# Installs the 'PyWavelets' library, which provides wavelet transform functions for signal processing, including denoising, feature extraction, and compression.\n",
        "# version: PyWavelets-1.8.0\n",
        "!pip install scikit-learn==1.2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zX9kQeDKEpb",
        "outputId": "b1c3cb4a-0bf9-4404-86b0-de4911c0e766"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n",
            "Collecting pyedflib\n",
            "  Downloading pyedflib-0.1.39.tar.gz (2.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from pyedflib) (1.26.4)\n",
            "Building wheels for collected packages: pyedflib\n",
            "  Building wheel for pyedflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyedflib: filename=pyEDFlib-0.1.39-cp311-cp311-linux_x86_64.whl size=2624427 sha256=dbc096a3cad23cea1462d51a9354e9f4f4f5a9aa621011168276bae8556ddf33\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/25/41/b9605de2c5973791e87828347971b06712b12a14add875bff6\n",
            "Successfully built pyedflib\n",
            "Installing collected packages: pyedflib\n",
            "Successfully installed pyedflib-0.1.39\n",
            "Collecting openneuro-py\n",
            "  Downloading openneuro_py-2024.2.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from openneuro-py)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: httpx>=0.15 in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (0.28.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (4.3.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (2.32.3)\n",
            "Collecting sgqlc (from openneuro-py)\n",
            "  Downloading sgqlc-16.4-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (4.67.1)\n",
            "Requirement already satisfied: typer[all] in /usr/local/lib/python3.11/dist-packages (from openneuro-py) (0.15.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.15->openneuro-py) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.15->openneuro-py) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->openneuro-py) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->openneuro-py) (2.3.0)\n",
            "Collecting graphql-core<4.0.0,>=3.2.4 (from sgqlc->openneuro-py)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "\u001b[33mWARNING: typer 0.15.1 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (8.1.8)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (4.12.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer[all]->openneuro-py) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer[all]->openneuro-py) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer[all]->openneuro-py) (2.18.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.15->openneuro-py) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer[all]->openneuro-py) (0.1.2)\n",
            "Downloading openneuro_py-2024.2.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading sgqlc-16.4-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphql-core, aiofiles, sgqlc, openneuro-py\n",
            "Successfully installed aiofiles-24.1.0 graphql-core-3.2.6 openneuro-py-2024.2.0 sgqlc-16.4\n",
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GCAEjAwO8QnW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f32943-2f6b-4229-e4c4-e633270bd858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Importing the Google Colab drive module\n",
        "from google.colab import drive\n",
        "# Mounting Google Drive to the Colab environment\n",
        "# This allows you to access files stored in your Google Drive directly from the Colab notebook.\n",
        "# The \"/content/drive\" is the directory where the Drive will be mounted.\n",
        "# After mounting, you can interact with your Drive files as if they were local files.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "# 'python-dotenv' is a library that allows you to manage environment variables from a `.env` file.\n",
        "# This is particularly useful for securely storing sensitive information such as API keys, database credentials, etc.\n",
        "# By using environment variables, you avoid hardcoding sensitive data directly in your code."
      ],
      "metadata": {
        "id": "lsSQtl4dKDqd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba5750c-6a61-4a2a-942a-06f2c3ae2071"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # The 'os' module is used to interact with the operating system, such as reading environment variables.\n",
        "from dotenv import load_dotenv  # 'load_dotenv' is used to load environment variables from a .env file.\n",
        "# Specify the path to the .env file\n",
        "# The .env file stores environment variables like API keys securely.\n",
        "# In this case, the .env file is located in the user's Google Drive.\n",
        "env_path = '/content/drive/My Drive/ColabEnvFiles/API_KEY.env'\n",
        "# Load the environment variables from the specified .env file\n",
        "load_dotenv(env_path)\n",
        "# Access the API key using the key name as defined in the .env file\n",
        "api_key = os.getenv(\"OPENNEURO_API_KEY\")\n",
        "# Check if the API key was successfully loaded\n",
        "if api_key:\n",
        "    print(\"API Key loaded successfully!\")  # Inform the user that the API key was loaded.\n",
        "else:\n",
        "    print(\"Failed to load API Key. Check your .env file and path.\")  # Error message if loading fails."
      ],
      "metadata": {
        "id": "dvPJONHsPIOa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8de7f9-2311-45f1-b878-6047598c8e33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openneuro\n",
        "\n",
        "# Prompt the user to enter the dataset ID\n",
        "dataset_id = input(\"Enter the dataset ID (e.g., ds002778): \")\n",
        "\n",
        "# Validate the input\n",
        "if not dataset_id:\n",
        "    raise ValueError(\"Dataset ID must be provided.\")\n",
        "\n",
        "print(f\"Processing dataset: {dataset_id}\")\n",
        "\n",
        "# Function to create a directory\n",
        "def create_directory(dir_path):\n",
        "    try:\n",
        "        # Attempt to create the directory\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "        print(f\"Directory created successfully at: {dir_path}\")\n",
        "    except PermissionError:\n",
        "        # Handle permission errors\n",
        "        print(f\"Permission denied: Unable to create directory at {dir_path}. Please check permissions.\")\n",
        "    except OSError as e:\n",
        "        # Handle other OS-related errors\n",
        "        print(f\"Error creating directory at {dir_path}: {e}\")\n",
        "    except Exception as e:\n",
        "        # Catch any unexpected errors\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "# Determine the target directory for the download\n",
        "target_dir = os.path.join(os.getcwd(), dataset_id)\n",
        "\n",
        "# Create the target directory\n",
        "create_directory(target_dir)\n",
        "\n",
        "# Download the entire dataset\n",
        "openneuro.download(dataset=dataset_id, target_dir=target_dir)\n",
        "\n",
        "print(f\"Dataset {dataset_id} downloaded successfully to {target_dir}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "449de3f680e24cadaddd251413ff5e91",
            "820ca87aacad464fad58e856d00b206c",
            "042c37871029455ba6520bd746cd81e1",
            "bdff0c8c4695403ea205babf293c8fb9",
            "b09c81b8112947ee81496f6999034d45",
            "821a6469654d4984a8d808b6048cf3bf",
            "79223bdab2b54e4090408e956803b42b",
            "73f11997d68c4828acf63c299760dc31",
            "7167cda1fc6e4089a79e7d2282370a0b",
            "70929768f257417ab630df139b6ccd0f",
            "011c2cc50d384de0ad7a0cdb28fbd66f"
          ]
        },
        "id": "q0PNakwqPQT8",
        "outputId": "6f77f1bc-2efe-43bb-bb25-574881296a13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the dataset ID (e.g., ds002778): ds002778\n",
            "Processing dataset: ds002778\n",
            "Directory created successfully at: /content/ds002778\n",
            "\n",
            "üëã Hello! This is openneuro-py 2024.2.0. Great to see you! ü§ó\n",
            "\n",
            "   üëâ Please report problems ü§Ø and bugs ü™≤ at\n",
            "      https://github.com/hoechenberger/openneuro-py/issues\n",
            "\n",
            "üåç Preparing to download ds002778 ‚Ä¶\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "üìÅ Traversing directories for ds002778 : 0 entities [00:00, ? entities/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "449de3f680e24cadaddd251413ff5e91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Retrieving up to 328 files (5 concurrent downloads). \n",
            "‚úÖ Finished downloading ds002778.\n",
            " \n",
            "üß† Please enjoy your brains.\n",
            " \n",
            "Dataset ds002778 downloaded successfully to /content/ds002778.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "target_dir = '/content/ds002778'\n",
        "\n",
        "subject_data = {}\n",
        "\n",
        "for subject_folder in os.listdir(target_dir):\n",
        "\n",
        "    if subject_folder.startswith('sub-'):\n",
        "        subject_id = subject_folder.split('-')[1]\n",
        "        print(f\"\\nProcessing subject: {subject_id}\")\n",
        "\n",
        "        if subject_id.startswith('pd'):\n",
        "            session_path = os.path.join(target_dir, subject_folder, 'ses-off', 'eeg')\n",
        "            session_type = 'ses-off'\n",
        "            json_path = os.path.join(target_dir, subject_folder, 'ses-off', 'beh')\n",
        "        elif subject_id.startswith('hc'):\n",
        "            session_path = os.path.join(target_dir, subject_folder, 'ses-hc', 'eeg')\n",
        "            session_type = 'ses-hc'\n",
        "            json_path = None\n",
        "        else:\n",
        "            print(f\"Unknown subject type for {subject_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        if not os.path.exists(session_path):\n",
        "            print(f\"No '{session_type}/eeg' folder found for subject {subject_id}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        bdf_file = None\n",
        "        for file in os.listdir(session_path):\n",
        "            if file.endswith('.bdf') and f\"sub-{subject_id}\" in file:\n",
        "                bdf_file = os.path.join(session_path, file)\n",
        "                break\n",
        "\n",
        "        json_file = None\n",
        "        if subject_id.startswith('pd') and json_path:\n",
        "            for file in os.listdir(json_path):\n",
        "                if file.endswith('.json'):\n",
        "                    json_file = os.path.join(json_path, file)\n",
        "                    break\n",
        "\n",
        "        subject_data[subject_id] = {\n",
        "            \"bdf_file\": bdf_file,\n",
        "            \"json_file\": json_file if subject_id.startswith('pd') else None\n",
        "        }\n",
        "\n",
        "        if bdf_file:\n",
        "            print(f\"‚úÖ Found EEG file: {bdf_file}\")\n",
        "        else:\n",
        "            print(f\"‚ùå No EEG file found for {subject_id}.\")\n",
        "\n",
        "        if json_file:\n",
        "            print(f\"‚úÖ Found JSON file: {json_file}\")\n",
        "        elif subject_id.startswith('pd'):\n",
        "            print(f\"‚ùå No JSON file found for {subject_id}.\")\n",
        "\n",
        "# Print final summary\n",
        "print(\"\\nüìù Summary of Collected Data:\")\n",
        "for subject, files in subject_data.items():\n",
        "    print(f\"Subject {subject}: EEG - {files['bdf_file']}, JSON - {files['json_file']}\")"
      ],
      "metadata": {
        "id": "qUgABcwjxycJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c29f475-42bc-4232-a9c4-c84eb64260e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing subject: hc8\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc8/ses-hc/eeg/sub-hc8_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd12\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd12/ses-off/eeg/sub-pd12_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd12/ses-off/beh/sub-pd12_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc25\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc25/ses-hc/eeg/sub-hc25_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd16\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd16/ses-off/eeg/sub-pd16_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd16/ses-off/beh/sub-pd16_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd17\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd17/ses-off/eeg/sub-pd17_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd17/ses-off/beh/sub-pd17_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc7\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc7/ses-hc/eeg/sub-hc7_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd19\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd19/ses-off/eeg/sub-pd19_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd19/ses-off/beh/sub-pd19_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd28\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd28/ses-off/eeg/sub-pd28_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd28/ses-off/beh/sub-pd28_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd23\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd23/ses-off/eeg/sub-pd23_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd23/ses-off/beh/sub-pd23_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc1\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc1/ses-hc/eeg/sub-hc1_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc33\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc33/ses-hc/eeg/sub-hc33_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc10\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc10/ses-hc/eeg/sub-hc10_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc2\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc2/ses-hc/eeg/sub-hc2_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd6\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd6/ses-off/eeg/sub-pd6_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd6/ses-off/beh/sub-pd6_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc20\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc20/ses-hc/eeg/sub-hc20_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd5\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd5/ses-off/eeg/sub-pd5_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd5/ses-off/beh/sub-pd5_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc30\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc30/ses-hc/eeg/sub-hc30_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc32\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc32/ses-hc/eeg/sub-hc32_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc24\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc24/ses-hc/eeg/sub-hc24_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd9\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd9/ses-off/eeg/sub-pd9_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd9/ses-off/beh/sub-pd9_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc29\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc29/ses-hc/eeg/sub-hc29_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd26\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd26/ses-off/eeg/sub-pd26_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd26/ses-off/beh/sub-pd26_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd22\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd22/ses-off/eeg/sub-pd22_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd22/ses-off/beh/sub-pd22_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc31\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc31/ses-hc/eeg/sub-hc31_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc4\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc4/ses-hc/eeg/sub-hc4_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: pd11\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd11/ses-off/eeg/sub-pd11_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd11/ses-off/beh/sub-pd11_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd14\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd14/ses-off/eeg/sub-pd14_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd14/ses-off/beh/sub-pd14_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd13\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd13/ses-off/eeg/sub-pd13_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd13/ses-off/beh/sub-pd13_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: pd3\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-pd3/ses-off/eeg/sub-pd3_ses-off_task-rest_eeg.bdf\n",
            "‚úÖ Found JSON file: /content/ds002778/sub-pd3/ses-off/beh/sub-pd3_ses-off_task-rest_beh.json\n",
            "\n",
            "Processing subject: hc18\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc18/ses-hc/eeg/sub-hc18_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "Processing subject: hc21\n",
            "‚úÖ Found EEG file: /content/ds002778/sub-hc21/ses-hc/eeg/sub-hc21_ses-hc_task-rest_eeg.bdf\n",
            "\n",
            "üìù Summary of Collected Data:\n",
            "Subject hc8: EEG - /content/ds002778/sub-hc8/ses-hc/eeg/sub-hc8_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd12: EEG - /content/ds002778/sub-pd12/ses-off/eeg/sub-pd12_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd12/ses-off/beh/sub-pd12_ses-off_task-rest_beh.json\n",
            "Subject hc25: EEG - /content/ds002778/sub-hc25/ses-hc/eeg/sub-hc25_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd16: EEG - /content/ds002778/sub-pd16/ses-off/eeg/sub-pd16_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd16/ses-off/beh/sub-pd16_ses-off_task-rest_beh.json\n",
            "Subject pd17: EEG - /content/ds002778/sub-pd17/ses-off/eeg/sub-pd17_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd17/ses-off/beh/sub-pd17_ses-off_task-rest_beh.json\n",
            "Subject hc7: EEG - /content/ds002778/sub-hc7/ses-hc/eeg/sub-hc7_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd19: EEG - /content/ds002778/sub-pd19/ses-off/eeg/sub-pd19_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd19/ses-off/beh/sub-pd19_ses-off_task-rest_beh.json\n",
            "Subject pd28: EEG - /content/ds002778/sub-pd28/ses-off/eeg/sub-pd28_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd28/ses-off/beh/sub-pd28_ses-off_task-rest_beh.json\n",
            "Subject pd23: EEG - /content/ds002778/sub-pd23/ses-off/eeg/sub-pd23_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd23/ses-off/beh/sub-pd23_ses-off_task-rest_beh.json\n",
            "Subject hc1: EEG - /content/ds002778/sub-hc1/ses-hc/eeg/sub-hc1_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc33: EEG - /content/ds002778/sub-hc33/ses-hc/eeg/sub-hc33_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc10: EEG - /content/ds002778/sub-hc10/ses-hc/eeg/sub-hc10_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc2: EEG - /content/ds002778/sub-hc2/ses-hc/eeg/sub-hc2_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd6: EEG - /content/ds002778/sub-pd6/ses-off/eeg/sub-pd6_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd6/ses-off/beh/sub-pd6_ses-off_task-rest_beh.json\n",
            "Subject hc20: EEG - /content/ds002778/sub-hc20/ses-hc/eeg/sub-hc20_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd5: EEG - /content/ds002778/sub-pd5/ses-off/eeg/sub-pd5_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd5/ses-off/beh/sub-pd5_ses-off_task-rest_beh.json\n",
            "Subject hc30: EEG - /content/ds002778/sub-hc30/ses-hc/eeg/sub-hc30_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc32: EEG - /content/ds002778/sub-hc32/ses-hc/eeg/sub-hc32_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc24: EEG - /content/ds002778/sub-hc24/ses-hc/eeg/sub-hc24_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd9: EEG - /content/ds002778/sub-pd9/ses-off/eeg/sub-pd9_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd9/ses-off/beh/sub-pd9_ses-off_task-rest_beh.json\n",
            "Subject hc29: EEG - /content/ds002778/sub-hc29/ses-hc/eeg/sub-hc29_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd26: EEG - /content/ds002778/sub-pd26/ses-off/eeg/sub-pd26_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd26/ses-off/beh/sub-pd26_ses-off_task-rest_beh.json\n",
            "Subject pd22: EEG - /content/ds002778/sub-pd22/ses-off/eeg/sub-pd22_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd22/ses-off/beh/sub-pd22_ses-off_task-rest_beh.json\n",
            "Subject hc31: EEG - /content/ds002778/sub-hc31/ses-hc/eeg/sub-hc31_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc4: EEG - /content/ds002778/sub-hc4/ses-hc/eeg/sub-hc4_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject pd11: EEG - /content/ds002778/sub-pd11/ses-off/eeg/sub-pd11_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd11/ses-off/beh/sub-pd11_ses-off_task-rest_beh.json\n",
            "Subject pd14: EEG - /content/ds002778/sub-pd14/ses-off/eeg/sub-pd14_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd14/ses-off/beh/sub-pd14_ses-off_task-rest_beh.json\n",
            "Subject pd13: EEG - /content/ds002778/sub-pd13/ses-off/eeg/sub-pd13_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd13/ses-off/beh/sub-pd13_ses-off_task-rest_beh.json\n",
            "Subject pd3: EEG - /content/ds002778/sub-pd3/ses-off/eeg/sub-pd3_ses-off_task-rest_eeg.bdf, JSON - /content/ds002778/sub-pd3/ses-off/beh/sub-pd3_ses-off_task-rest_beh.json\n",
            "Subject hc18: EEG - /content/ds002778/sub-hc18/ses-hc/eeg/sub-hc18_ses-hc_task-rest_eeg.bdf, JSON - None\n",
            "Subject hc21: EEG - /content/ds002778/sub-hc21/ses-hc/eeg/sub-hc21_ses-hc_task-rest_eeg.bdf, JSON - None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# raw_fname = target_dir\n",
        "\n",
        "# for subject_folder in os.listdir(raw_fname):\n",
        "#     if subject_folder.startswith('sub-'):\n",
        "#         subject_id = subject_folder.split('-')[1]\n",
        "#         print(f\"Processing subject: {subject_id}\")\n",
        "\n",
        "#         if subject_id.startswith('pd'):\n",
        "#             session_path = os.path.join(raw_fname, subject_folder, 'ses-off', 'eeg')\n",
        "#             session_type = 'ses-off'\n",
        "#         elif subject_id.startswith('hc'):\n",
        "#             session_path = os.path.join(raw_fname, subject_folder, 'ses-hc', 'eeg')\n",
        "#             session_type = 'ses-hc'\n",
        "#         else:\n",
        "#             print(f\"Unknown subject type for {subject_id}. Skipping.\")\n",
        "#             continue\n",
        "\n",
        "#         if not os.path.exists(session_path):\n",
        "#             print(f\"No '{session_type}/eeg' folder found for subject {subject_id}. Skipping.\")\n",
        "#             continue\n",
        "\n",
        "#         bdf_file = None\n",
        "#         for file in os.listdir(session_path):\n",
        "#             if file.endswith('.bdf') and f\"sub-{subject_id}\" in file:\n",
        "#                 bdf_file = os.path.join(session_path, file)\n",
        "#                 break\n",
        "\n",
        "#         if bdf_file:\n",
        "#             print(f\"Found EEG file for subject {subject_id} ({session_type}): {bdf_file}\")\n",
        "#             try:\n",
        "#                 with open(bdf_file, 'rb') as f:\n",
        "#                     header = f.read(256)\n",
        "#                     print(f\"Header for subject {subject_id}:\\n{header}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error reading file {bdf_file}: {e}\")\n",
        "#         else:\n",
        "#             print(f\"EEG .bdf file not found for subject {subject_id} in {session_type} session.\")\n"
      ],
      "metadata": {
        "id": "luHlXWSsy8Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correct running making changes to upper one(final)\n",
        "import os\n",
        "import openneuro\n",
        "import mne\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.signal import welch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "subject_dirs = [d for d in os.listdir(target_dir) if d.startswith('sub-')]\n",
        "\n",
        "print(f\"Found {len(subject_dirs)} subjects in the dataset.\")\n",
        "\n",
        "features_list = []\n",
        "epoch_length_sec = 5\n",
        "\n",
        "for subject in subject_dirs:\n",
        "    print(f\"Processing subject: {subject}\")\n",
        "\n",
        "    if 'sub-pd' in subject:\n",
        "        raw_fname = os.path.join(target_dir, subject, 'ses-off', 'eeg', f'{subject}_ses-off_task-rest_eeg.bdf')\n",
        "    else:\n",
        "        raw_fname = os.path.join(target_dir, subject, 'ses-hc', 'eeg', f'{subject}_ses-hc_task-rest_eeg.bdf')\n",
        "\n",
        "    if not os.path.exists(raw_fname):\n",
        "        print(f\"EEG data file not found for {subject}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        raw = mne.io.read_raw_bdf(raw_fname, preload=True)\n",
        "        raw_filtered = raw.filter(l_freq=0.5, h_freq=50, fir_design='firwin', verbose=True)\n",
        "        montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "        raw_filtered.set_montage(montage, on_missing=\"ignore\")\n",
        "\n",
        "        ica = mne.preprocessing.ICA(n_components=20, random_state=42, max_iter=1000)\n",
        "        ica.fit(raw_filtered)\n",
        "        raw_cleaned = ica.apply(raw_filtered)\n",
        "\n",
        "        sfreq = raw.info['sfreq']\n",
        "        n_samples_per_epoch = int(epoch_length_sec * sfreq)\n",
        "        n_epochs = int(raw_filtered.n_times // n_samples_per_epoch)\n",
        "\n",
        "        events = np.array([[i * n_samples_per_epoch, 0, i] for i in range(n_epochs)])\n",
        "\n",
        "        event_id = {f\"epoch_{i}\": i for i in range(n_epochs)}\n",
        "\n",
        "        epochs = mne.Epochs(raw_filtered, events, event_id=event_id, tmin=0, tmax=epoch_length_sec, baseline=None, detrend=1, preload=True)\n",
        "\n",
        "        freq_bands = {\n",
        "            'delta': (1, 4),\n",
        "            'theta': (4, 8),\n",
        "            'alpha': (8, 12),\n",
        "            'beta': (12, 30),\n",
        "            'gamma': (30, 50)\n",
        "        }\n",
        "\n",
        "        def compute_band_power(epoch_data, sfreq, freq_bands):\n",
        "            power_features = {}\n",
        "            for band, (low, high) in freq_bands.items():\n",
        "                f, psd = welch(epoch_data, sfreq, nperseg=1024)\n",
        "                psd = psd[(f >= low) & (f <= high)]\n",
        "                power = np.sum(psd)\n",
        "                power_features[f'{band}_power'] = power\n",
        "            return power_features\n",
        "\n",
        "        for epoch_idx, epoch_data in enumerate(epochs.get_data()):\n",
        "            band_power = compute_band_power(epoch_data.mean(axis=0), raw.info['sfreq'], freq_bands)\n",
        "            band_power['subject'] = subject\n",
        "            band_power['epoch'] = epoch_idx\n",
        "            features_list.append(band_power)\n",
        "\n",
        "        print(f\"EEG data for {subject} loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data for subject {subject}: {e}\")\n",
        "\n",
        "print(f\"Total epochs processed: {len(features_list)}\")\n",
        "\n",
        "if features_list:\n",
        "    features_df = pd.DataFrame(features_list)\n",
        "    features_df.to_csv(\"eeg_features.csv\", index=False)\n",
        "    print(\"Feature extraction complete. Features saved to 'eeg_features.csv'.\")\n",
        "else:\n",
        "    print(\"No features extracted. The CSV will not be created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMm3TKPz0Kmp",
        "outputId": "127225a3-a78b-4ed9-ef52-74f31f4a8511"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31 subjects in the dataset.\n",
            "Processing subject: sub-hc8\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc8/ses-hc/eeg/sub-hc8_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 7.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc8 loaded successfully.\n",
            "Processing subject: sub-pd12\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd12/ses-off/eeg/sub-pd12_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 105983  =      0.000 ...   206.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 14.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "41 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 41 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd12 loaded successfully.\n",
            "Processing subject: sub-hc25\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc25/ses-hc/eeg/sub-hc25_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 103423  =      0.000 ...   201.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc25 loaded successfully.\n",
            "Processing subject: sub-pd16\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd16/ses-off/eeg/sub-pd16_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96255  =      0.000 ...   187.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 6.9s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd16 loaded successfully.\n",
            "Processing subject: sub-pd17\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd17/ses-off/eeg/sub-pd17_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96767  =      0.000 ...   188.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 6.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd17 loaded successfully.\n",
            "Processing subject: sub-hc7\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc7/ses-hc/eeg/sub-hc7_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 98303  =      0.000 ...   191.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 16.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc7 loaded successfully.\n",
            "Processing subject: sub-pd19\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd19/ses-off/eeg/sub-pd19_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 94719  =      0.000 ...   184.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 8.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "1 bad epochs dropped\n",
            "EEG data for sub-pd19 loaded successfully.\n",
            "Processing subject: sub-pd28\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd28/ses-off/eeg/sub-pd28_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 105471  =      0.000 ...   205.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 7.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "41 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 41 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd28 loaded successfully.\n",
            "Processing subject: sub-pd23\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd23/ses-off/eeg/sub-pd23_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 104447  =      0.000 ...   203.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 17.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd23 loaded successfully.\n",
            "Processing subject: sub-hc1\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc1/ses-hc/eeg/sub-hc1_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 98303  =      0.000 ...   191.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 15.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc1 loaded successfully.\n",
            "Processing subject: sub-hc33\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc33/ses-hc/eeg/sub-hc33_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97279  =      0.000 ...   189.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 8.7s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "1 bad epochs dropped\n",
            "EEG data for sub-hc33 loaded successfully.\n",
            "Processing subject: sub-hc10\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc10/ses-hc/eeg/sub-hc10_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 102911  =      0.000 ...   200.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 8.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc10 loaded successfully.\n",
            "Processing subject: sub-hc2\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc2/ses-hc/eeg/sub-hc2_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 99327  =      0.000 ...   193.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 8.4s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc2 loaded successfully.\n",
            "Processing subject: sub-pd6\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd6/ses-off/eeg/sub-pd6_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 13.4s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd6 loaded successfully.\n",
            "Processing subject: sub-hc20\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc20/ses-hc/eeg/sub-hc20_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 94207  =      0.000 ...   183.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 7.9s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "36 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 36 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc20 loaded successfully.\n",
            "Processing subject: sub-pd5\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd5/ses-off/eeg/sub-pd5_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 100863  =      0.000 ...   196.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 10.0s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "39 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 39 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd5 loaded successfully.\n",
            "Processing subject: sub-hc30\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc30/ses-hc/eeg/sub-hc30_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96767  =      0.000 ...   188.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 3.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc30 loaded successfully.\n",
            "Processing subject: sub-hc32\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc32/ses-hc/eeg/sub-hc32_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 100351  =      0.000 ...   195.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 8.0s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "39 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 39 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc32 loaded successfully.\n",
            "Processing subject: sub-hc24\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc24/ses-hc/eeg/sub-hc24_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 98303  =      0.000 ...   191.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 4.3s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc24 loaded successfully.\n",
            "Processing subject: sub-pd9\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd9/ses-off/eeg/sub-pd9_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 11.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd9 loaded successfully.\n",
            "Processing subject: sub-hc29\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc29/ses-hc/eeg/sub-hc29_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 101887  =      0.000 ...   198.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 6.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "39 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 39 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc29 loaded successfully.\n",
            "Processing subject: sub-pd26\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd26/ses-off/eeg/sub-pd26_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 97791  =      0.000 ...   190.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 7.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "38 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 38 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd26 loaded successfully.\n",
            "Processing subject: sub-pd22\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd22/ses-off/eeg/sub-pd22_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96255  =      0.000 ...   187.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 5.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd22 loaded successfully.\n",
            "Processing subject: sub-hc31\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc31/ses-hc/eeg/sub-hc31_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95743  =      0.000 ...   186.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 10.8s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc31 loaded successfully.\n",
            "Processing subject: sub-hc4\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc4/ses-hc/eeg/sub-hc4_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 92671  =      0.000 ...   180.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 165.4s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "36 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py:123: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 36 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc4 loaded successfully.\n",
            "Processing subject: sub-pd11\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd11/ses-off/eeg/sub-pd11_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95231  =      0.000 ...   185.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 169.5s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/decomposition/_fastica.py:123: ConvergenceWarning: FastICA did not converge. Consider increasing tolerance or the maximum number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd11 loaded successfully.\n",
            "Processing subject: sub-pd14\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd14/ses-off/eeg/sub-pd14_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 149503  =      0.000 ...   291.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 11.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "58 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 58 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd14 loaded successfully.\n",
            "Processing subject: sub-pd13\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd13/ses-off/eeg/sub-pd13_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95231  =      0.000 ...   185.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 9.9s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-pd13 loaded successfully.\n",
            "Processing subject: sub-pd3\n",
            "Extracting EDF parameters from /content/ds002778/sub-pd3/ses-off/eeg/sub-pd3_ses-off_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 102399  =      0.000 ...   199.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 10.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "40 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 40 events and 2561 original time points ...\n",
            "1 bad epochs dropped\n",
            "EEG data for sub-pd3 loaded successfully.\n",
            "Processing subject: sub-hc18\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc18/ses-hc/eeg/sub-hc18_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 95231  =      0.000 ...   185.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n",
            "Selecting by number: 20 components\n",
            "Fitting ICA took 11.6s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc18 loaded successfully.\n",
            "Processing subject: sub-hc21\n",
            "Extracting EDF parameters from /content/ds002778/sub-hc21/ses-hc/eeg/sub-hc21_ses-hc_task-rest_eeg.bdf...\n",
            "BDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 96767  =      0.000 ...   188.998 secs...\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 50 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 50.00 Hz\n",
            "- Upper transition bandwidth: 12.50 Hz (-6 dB cutoff frequency: 56.25 Hz)\n",
            "- Filter length: 3381 samples (6.604 s)\n",
            "\n",
            "Fitting ICA to data using 40 channels (please be patient, this may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting by number: 20 components\n",
            "Fitting ICA took 5.1s.\n",
            "Applying ICA to Raw instance\n",
            "    Transforming to ICA space (20 components)\n",
            "    Zeroing out 0 ICA components\n",
            "    Projecting back using 40 PCA components\n",
            "Not setting metadata\n",
            "37 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 37 events and 2561 original time points ...\n",
            "0 bad epochs dropped\n",
            "EEG data for sub-hc21 loaded successfully.\n",
            "Total epochs processed: 1198\n",
            "Feature extraction complete. Features saved to 'eeg_features.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "target_dir = '/content/ds002778'\n",
        "metadata_list = []\n",
        "subject_dirs = [d for d in os.listdir(target_dir) if d.startswith('sub-pd')]\n",
        "\n",
        "print(f\"Found {len(subject_dirs)} Parkinson's subjects with possible JSON metadata.\")\n",
        "for subject in subject_dirs:\n",
        "    print(f\"Processing JSON for {subject}...\")\n",
        "\n",
        "    json_path = os.path.join(target_dir, subject, 'ses-off', 'beh')\n",
        "\n",
        "    if not os.path.exists(json_path):\n",
        "        print(f\"No JSON folder found for {subject}. Skipping.\")\n",
        "        continue\n",
        "    json_file = None\n",
        "    for file in os.listdir(json_path):\n",
        "        if file.endswith('.json'):\n",
        "            json_file = os.path.join(json_path, file)\n",
        "            break\n",
        "\n",
        "    if not json_file:\n",
        "        print(f\"No JSON file found for {subject}. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with open(json_file, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        metadata_entry = {\n",
        "            \"subject\": subject,\n",
        "            \"Lev_Dose_mg\": data[\"meds\"][\"Lev\"][\"Dose (mg)\"] if \"Lev\" in data[\"meds\"] else None,\n",
        "            \"Lev_hours_since_meds\": data[\"meds\"][\"Lev\"][\"hours since meds\"] if \"Lev\" in data[\"meds\"] else None,\n",
        "            \"Lev_times_per_day\": data[\"meds\"][\"Lev\"][\"times/day\"] if \"Lev\" in data[\"meds\"] else None,\n",
        "            \"Ras_Dose_mg\": data[\"meds\"][\"Ras\"][\"Dose (mg)\"] if \"Ras\" in data[\"meds\"] else None,\n",
        "            \"Ras_hours_since_meds\": data[\"meds\"][\"Ras\"][\"hours since meds\"] if \"Ras\" in data[\"meds\"] else None,\n",
        "            \"Ras_times_per_day\": data[\"meds\"][\"Ras\"][\"times/day\"] if \"Ras\" in data[\"meds\"] else None,\n",
        "            \"Beck_Score\": data[\"questionairres\"][\"Beck\"] if \"Beck\" in data[\"questionairres\"] else None,\n",
        "            \"Bradykinesia_UPDRS\": data[\"questionairres\"][\"Brady kinesia UPDRS\"] if \"Brady kinesia UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"H_Y_Stage\": data[\"questionairres\"][\"H&Y\"] if \"H&Y\" in data[\"questionairres\"] else None,\n",
        "            \"Left_UPDRS\": data[\"questionairres\"][\"Left UPDRS\"] if \"Left UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Rest_Tremor_UPDRS\": data[\"questionairres\"][\"Rest Tremor UPDRS\"] if \"Rest Tremor UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Right_UPDRS\": data[\"questionairres\"][\"Right UPDRS\"] if \"Right UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Rigidity_UPDRS\": data[\"questionairres\"][\"Rigidity UPDRS\"] if \"Rigidity UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"Total_UPDRS\": data[\"questionairres\"][\"Total UPDRS\"] if \"Total UPDRS\" in data[\"questionairres\"] else None,\n",
        "            \"UPDRS_18_26\": data[\"questionairres\"][\"UPDRS 18-26\"] if \"UPDRS 18-26\" in data[\"questionairres\"] else None\n",
        "        }\n",
        "\n",
        "        metadata_list.append(metadata_entry)\n",
        "        print(f\" JSON processed for {subject}.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing JSON for {subject}: {e}\")\n",
        "if metadata_list:\n",
        "    metadata_df = pd.DataFrame(metadata_list)\n",
        "    metadata_df.to_csv(\"json_metadata.csv\", index=False)\n",
        "    print(\" JSON metadata saved to 'json_metadata.csv'.\")\n",
        "else:\n",
        "    print(\" No JSON data extracted.\")"
      ],
      "metadata": {
        "id": "DZrGsaon9S8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76c42d2-bafb-47c9-d35b-78c05d2ef290"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15 Parkinson's subjects with possible JSON metadata.\n",
            "Processing JSON for sub-pd12...\n",
            " JSON processed for sub-pd12.\n",
            "Processing JSON for sub-pd16...\n",
            " JSON processed for sub-pd16.\n",
            "Processing JSON for sub-pd17...\n",
            " JSON processed for sub-pd17.\n",
            "Processing JSON for sub-pd19...\n",
            " JSON processed for sub-pd19.\n",
            "Processing JSON for sub-pd28...\n",
            " JSON processed for sub-pd28.\n",
            "Processing JSON for sub-pd23...\n",
            " JSON processed for sub-pd23.\n",
            "Processing JSON for sub-pd6...\n",
            " JSON processed for sub-pd6.\n",
            "Processing JSON for sub-pd5...\n",
            " JSON processed for sub-pd5.\n",
            "Processing JSON for sub-pd9...\n",
            " JSON processed for sub-pd9.\n",
            "Processing JSON for sub-pd26...\n",
            " JSON processed for sub-pd26.\n",
            "Processing JSON for sub-pd22...\n",
            " JSON processed for sub-pd22.\n",
            "Processing JSON for sub-pd11...\n",
            " JSON processed for sub-pd11.\n",
            "Processing JSON for sub-pd14...\n",
            " JSON processed for sub-pd14.\n",
            "Processing JSON for sub-pd13...\n",
            " JSON processed for sub-pd13.\n",
            "Processing JSON for sub-pd3...\n",
            " JSON processed for sub-pd3.\n",
            " JSON metadata saved to 'json_metadata.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load EEG features\n",
        "eeg_features_df = pd.read_csv(\"eeg_features.csv\")\n",
        "print(f\"EEG features loaded: {eeg_features_df.shape}\")\n",
        "\n",
        "# Load JSON metadata (only PD subjects have this)\n",
        "json_metadata_df = pd.read_csv(\"json_metadata.csv\")\n",
        "print(f\"JSON metadata loaded: {json_metadata_df.shape}\")\n",
        "\n",
        "# Merge with left join to retain all EEG subjects\n",
        "merged_df = pd.merge(eeg_features_df, json_metadata_df, on=\"subject\", how=\"left\")\n",
        "\n",
        "# Identify HC subjects (those with missing H&Y values)\n",
        "merged_df[\"is_hc\"] = merged_df[\"H_Y_Stage\"].isna()\n",
        "\n",
        "# Define risk percentage function\n",
        "def calculate_risk_percentage(hy_stage, is_hc):\n",
        "    if is_hc:\n",
        "        return 0  # HC subjects have 0% risk\n",
        "    elif hy_stage <= 1.0:\n",
        "        return 20\n",
        "    elif hy_stage >= 3.0:\n",
        "        return 100\n",
        "    else:\n",
        "        return 20 + (hy_stage - 1.0) * ((100 - 20) / (3.0 - 1.0))\n",
        "\n",
        "# Apply risk calculation\n",
        "merged_df[\"risk_percentage\"] = merged_df.apply(lambda row: calculate_risk_percentage(row[\"H_Y_Stage\"], row[\"is_hc\"]), axis=1)\n",
        "\n",
        "# Save the updated dataset\n",
        "merged_df.to_csv(\"merged_dataset_with_risk.csv\", index=False)\n",
        "print(f\" Merged dataset saved as 'merged_dataset_with_risk.csv' with shape: {merged_df.shape}\")\n"
      ],
      "metadata": {
        "id": "GpE-3lIQoj83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55182195-6355-459e-e161-7b5eaa95cf40"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG features loaded: (1198, 7)\n",
            "JSON metadata loaded: (15, 16)\n",
            " Merged dataset saved as 'merged_dataset_with_risk.csv' with shape: (1198, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "Ynv-dHqN9ZTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "426ea465-9b94-478c-aadf-46d1412dcc49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv(\"merged_dataset_with_risk.csv\")\n",
        "eeg_features = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "if 'risk_percentage' not in df.columns:\n",
        "    raise ValueError(\"The dataset must contain a 'risk_percentage' column!\")\n",
        "X = df[eeg_features]\n",
        "y = df['risk_percentage']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=None)\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "test_df = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "train_df.to_csv(\"train_set.csv\", index=False)\n",
        "test_df.to_csv(\"test_set.csv\", index=False)\n",
        "print(\"Train and test datasets created successfully!\")"
      ],
      "metadata": {
        "id": "czwwfEY8-BfQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96188020-59ac-4566-e920-0558aa8f1d38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and test datasets created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "# import joblib\n",
        "\n",
        "# train_df = pd.read_csv(\"train_set.csv\")\n",
        "# test_df = pd.read_csv(\"test_set.csv\")\n",
        "# eeg_features = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "# X_train, y_train = train_df[eeg_features], train_df['risk_percentage']\n",
        "# X_test, y_test = test_df[eeg_features], test_df['risk_percentage']\n",
        "\n",
        "# rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "# rf_model.fit(X_train, y_train)\n",
        "\n",
        "# y_pred = rf_model.predict(X_test)\n",
        "# mae = mean_absolute_error(y_test, y_pred)\n",
        "# mse = mean_squared_error(y_test, y_pred)\n",
        "# r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# print(f\"Model Performance:\\n MAE: {mae:.2f}, MSE: {mse:.2f}, R¬≤: {r2:.2f}\")\n",
        "\n",
        "# joblib.dump(rf_model, \"eeg_risk_prediction_model.pkl\")\n",
        "# print(\"Model saved as 'eeg_risk_prediction_model.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vOzJ-gFTBeN",
        "outputId": "9e435d88-1d30-41b1-b0ce-7ce4c45780df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance:\n",
            " MAE: 40.74, MSE: 1875.50, R¬≤: -0.02\n",
            "Model saved as 'eeg_risk_prediction_model.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade scikit-learn xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8quM_XdgUYq9",
        "outputId": "2e0ef412-8264-4a5a-f4b2-ae7e8ff3d433"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "Successfully installed scikit-learn-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fUKlTC4bVH0U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300],  # Number of boosting rounds\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],  # Step size shrinkage\n",
        "    'max_depth': [3, 5, 7, 10],  # Depth of trees\n",
        "    'subsample': [0.6, 0.8, 1.0],  # Fraction of samples per tree\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features per tree\n",
        "    'gamma': [0, 0.1, 0.2, 0.3],  # Minimum loss reduction\n",
        "    'reg_lambda': [0, 1, 5, 10]  # L2 regularization\n",
        "}\n",
        "\n",
        "xgb_reg = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
        "random_search = RandomizedSearchCV(xgb_reg, param_grid, n_iter=20, cv=5, scoring='r2', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "best_xgb = random_search.best_estimator_\n",
        "\n",
        "y_pred_tuned = best_xgb.predict(X_test)\n",
        "mae_tuned = mean_absolute_error(y_test, y_pred_tuned)\n",
        "mse_tuned = mean_squared_error(y_test, y_pred_tuned)\n",
        "r2_tuned = r2_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(\"\\nTuned Model Performance:\")\n",
        "print(f\"MAE: {mae_tuned:.2f}, MSE: {mse_tuned:.2f}, R¬≤: {r2_tuned:.2f}\")\n",
        "\n",
        "joblib.dump(best_xgb, \"eeg_risk_prediction_xgboost_tuned.pkl\")\n",
        "print(\"Tuned model saved as 'eeg_risk_prediction_xgboost_tuned.pkl'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "GoAEQxn7TU-2",
        "outputId": "fe51ba68-f5a2-4077-c80d-eab922fde077"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BrokenProcessPool",
          "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/multiprocessing/queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: Can't get attribute '_PredictScorer' on <module 'sklearn.metrics._scorer' from '/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_scorer.py'>\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-05704ec27232>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mxgb_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reg:squarederror\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mbest_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0mThis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0minstead\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0msnippet\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0msince\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mused\u001b[0m \u001b[0mtwice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0mhere\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mHalvingRandomSearchCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         \"\"\"\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m             {\n\u001b[0;32m-> 1768\u001b[0;31m             'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n\u001b[0m\u001b[1;32m   1769\u001b[0m                                           mask = False),\n\u001b[1;32m   1770\u001b[0m             \u001b[0;34m'param_gamma'\u001b[0m  \u001b[0;34m:\u001b[0m \u001b[0mmasked_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mvalid_refit_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m         if (\n\u001b[1;32m    823\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mbe\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mReturns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1752\u001b[0m             \u001b[0;31m# worker traceback.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1754\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         \u001b[0;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m             \u001b[0merror_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;31m# be returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import lightgbm as lgb\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# # Define LightGBM model\n",
        "# lgb_reg = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.05, max_depth=5, random_state=42)\n",
        "\n",
        "# # Train model\n",
        "# lgb_reg.fit(X_train, y_train)\n",
        "\n",
        "# # Predict\n",
        "# y_pred = lgb_reg.predict(X_test)\n",
        "\n",
        "# # Evaluate performance\n",
        "# print(f\"MAE: {mean_absolute_error(y_test, y_pred):.2f}\")\n",
        "# print(f\"MSE: {mean_squared_error(y_test, y_pred):.2f}\")\n",
        "# print(f\"R¬≤: {r2_score(y_test, y_pred):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-YuIYIaYytK",
        "outputId": "50e0518c-e84e-4238-9784-0333df7d5ed0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001692 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1157\n",
            "[LightGBM] [Info] Number of data points in the train set: 958, number of used features: 5\n",
            "[LightGBM] [Info] Start training from score 39.290188\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "MAE: 26.82\n",
            "MSE: 1237.03\n",
            "R¬≤: 0.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRo-v_iYz-sQ",
        "outputId": "a4279252-3056-423b-b065-3e62a6acd7f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (1.26.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne-connectivity\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSX53bA30BnU",
        "outputId": "2579a618-db43-4636-bd81-2b52beea9cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne-connectivity in /usr/local/lib/python3.11/dist-packages (0.7.0)\n",
            "Requirement already satisfied: mne>=1.6 in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (1.9.0)\n",
            "Requirement already satisfied: netCDF4>=1.6.5 in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (1.7.2)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (4.67.1)\n",
            "Requirement already satisfied: xarray>=2023.11.0 in /usr/local/lib/python3.11/dist-packages (from mne-connectivity) (2025.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.6->mne-connectivity) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne>=1.6->mne-connectivity) (3.1.5)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.6->mne-connectivity) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne>=1.6->mne-connectivity) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne>=1.6->mne-connectivity) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne>=1.6->mne-connectivity) (1.8.2)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.6.5->mne-connectivity) (1.6.4.post1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4>=1.6.5->mne-connectivity) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.2->mne-connectivity) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.2->mne-connectivity) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.2->mne-connectivity) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.6->mne-connectivity) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.6->mne-connectivity) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.6->mne-connectivity) (4.55.8)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.6->mne-connectivity) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.6->mne-connectivity) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.6->mne-connectivity) (3.2.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.6->mne-connectivity) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne>=1.6->mne-connectivity) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->mne-connectivity) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne>=1.6->mne-connectivity) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.6->mne-connectivity) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.6->mne-connectivity) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne>=1.6->mne-connectivity) (2.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "from mne_connectivity import spectral_connectivity"
      ],
      "metadata": {
        "id": "xXH1DKuf0ngd",
        "outputId": "771ff405-bf0e-4ef8-eac3-d34af27ede31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'spectral_connectivity' from 'mne_connectivity' (/usr/local/lib/python3.11/dist-packages/mne_connectivity/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-d32d08a2e8a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmne_connectivity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectral_connectivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'spectral_connectivity' from 'mne_connectivity' (/usr/local/lib/python3.11/dist-packages/mne_connectivity/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mne\n",
        "print(mne.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzlEvc4i0W9s",
        "outputId": "e7c9c1aa-9a20-4469-84e7-d3e86bf5ef86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pywt\n",
        "import mne\n",
        "from mne.connectivity import spectral_connectivity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "neP7ERT10M5U",
        "outputId": "64643a8f-fde4-4107-a10e-97b992fc9011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mne.connectivity'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-05490b964303>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectivity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectral_connectivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mne.connectivity'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mne numpy scipy pandas pywt xgboost lightgbm scikit-learn tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXrAt3R6aYrR",
        "outputId": "765bdd17-2c5e-4b4e-e4ba-786ee97ef794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pywt (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pywt\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mne\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import entropy\n",
        "import pywt\n",
        "from mne.connectivity import spectral_connectivity\n",
        "\n",
        "# Load and preprocess EEG data\n",
        "def load_eeg_data(file_path):\n",
        "    raw = mne.io.read_raw_bdf(file_path, preload=True)\n",
        "    raw.filter(l_freq=0.5, h_freq=50)\n",
        "    return raw\n",
        "\n",
        "# Compute power spectral density (PSD) features\n",
        "def compute_band_power(epoch_data, sfreq):\n",
        "    bands = {'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 12), 'beta': (12, 30), 'gamma': (30, 50)}\n",
        "    psd_features = {}\n",
        "\n",
        "    for band, (low, high) in bands.items():\n",
        "        f, psd = welch(epoch_data, sfreq, nperseg=1024)\n",
        "        psd = psd[(f >= low) & (f <= high)]\n",
        "        psd_features[f'{band}_power'] = np.sum(psd)\n",
        "\n",
        "    return psd_features\n",
        "\n",
        "# Compute spectral entropy\n",
        "def spectral_entropy(epoch_data):\n",
        "    psd = np.abs(np.fft.fft(epoch_data))**2\n",
        "    return entropy(psd)\n",
        "\n",
        "# Compute Hjorth mobility and complexity\n",
        "def hjorth_params(epoch_data):\n",
        "    diff1 = np.diff(epoch_data)\n",
        "    diff2 = np.diff(diff1)\n",
        "    mobility = np.sqrt(np.var(diff1) / np.var(epoch_data))\n",
        "    complexity = np.sqrt(np.var(diff2) / np.var(diff1)) / mobility\n",
        "    return mobility, complexity\n",
        "\n",
        "# Compute wavelet entropy\n",
        "def wavelet_features(epoch_data):\n",
        "    coeffs = pywt.wavedec(epoch_data, 'db4', level=4)\n",
        "    return np.std(coeffs[0]), entropy(np.abs(coeffs[0]))\n",
        "\n",
        "# Compute EEG coherence (connectivity between channels)\n",
        "def compute_coherence(raw):\n",
        "    con, _, _, _, _ = spectral_connectivity(raw.get_data(), method='coh', sfreq=raw.info['sfreq'], fmin=8, fmax=12)\n",
        "    return np.mean(con)\n",
        "\n",
        "# Main processing loop\n",
        "features_list = []\n",
        "eeg_dir = \"your_eeg_data_folder\"\n",
        "\n",
        "for file in os.listdir(eeg_dir):\n",
        "    if file.endswith('.bdf'):\n",
        "        raw = load_eeg_data(os.path.join(eeg_dir, file))\n",
        "        sfreq = raw.info['sfreq']\n",
        "\n",
        "        for epoch_data in raw.get_data():\n",
        "            features = compute_band_power(epoch_data, sfreq)\n",
        "            features['spectral_entropy'] = spectral_entropy(epoch_data)\n",
        "            features['hjorth_mobility'], features['hjorth_complexity'] = hjorth_params(epoch_data)\n",
        "            features['wavelet_std'], features['wavelet_entropy'] = wavelet_features(epoch_data)\n",
        "            features['coherence'] = compute_coherence(raw)\n",
        "            features['subject'] = file.split('_')[0]\n",
        "            features_list.append(features)\n",
        "\n",
        "# Save to CSV\n",
        "df = pd.DataFrame(features_list)\n",
        "df.to_csv(\"eeg_features_advanced.csv\", index=False)\n",
        "print(\"Feature extraction complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "g4xNaPKzaWo6",
        "outputId": "812fd758-440e-4b9a-dc51-7bccf1a1e244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mne.connectivity'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-75b8c2cd7a79>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mentropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectivity\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspectral_connectivity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load and preprocess EEG data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mne.connectivity'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.utils import shuffle\n",
        "# from keras_tuner.tuners import RandomSearch\n",
        "# import random\n",
        "\n",
        "# # Set random seeds for reproducibility\n",
        "# np.random.seed(42)\n",
        "# random.seed(42)\n",
        "# tf.random.set_seed(42)\n",
        "\n",
        "# # Load EEG datasets\n",
        "# train_df = pd.read_csv(\"train_set.csv\")\n",
        "# test_df = pd.read_csv(\"test_set.csv\")\n",
        "\n",
        "# # Feature selection - Only EEG features\n",
        "# eeg_features = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "\n",
        "# # Extract features and labels\n",
        "# X_train = train_df[eeg_features].values\n",
        "# X_test = test_df[eeg_features].values\n",
        "# y_train = train_df['risk_percentage'].values  # Change label to risk percentage\n",
        "# y_test = test_df['risk_percentage'].values\n",
        "\n",
        "# # Normalize data\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# # Reshape for CNN input (1D Conv)\n",
        "# X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
        "# X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
        "\n",
        "# # Define CNN model using Keras Tuner\n",
        "# def build_cnn_model(hp):\n",
        "#     model = Sequential()\n",
        "\n",
        "#     model.add(Conv1D(\n",
        "#         filters=hp.Int('filters', min_value=32, max_value=128, step=32),\n",
        "#         kernel_size=hp.Int('kernel_size', min_value=3, max_value=7, step=2),\n",
        "#         activation='relu',\n",
        "#         padding='same',\n",
        "#         input_shape=(X_train_scaled.shape[1], 1)\n",
        "#     ))\n",
        "#     model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#     model.add(Flatten())\n",
        "\n",
        "#     for i in range(hp.Int('num_dense_layers', 1, 3)):\n",
        "#         model.add(Dense(\n",
        "#             units=hp.Int(f'units_dense_{i}', min_value=32, max_value=128, step=32),\n",
        "#             activation='relu'\n",
        "#         ))\n",
        "#         model.add(Dropout(hp.Float(f'dropout_dense_{i}', min_value=0.1, max_value=0.5, step=0.1)))\n",
        "\n",
        "#     # Output layer for risk percentage (0-100)\n",
        "#     model.add(Dense(1, activation='sigmoid'))  # Sigmoid to scale output between 0 and 1\n",
        "\n",
        "#     optimizer = Adam(\n",
        "#         learning_rate=hp.Choice('learning_rate', values=[1e-3, 5e-4, 1e-4])\n",
        "#     )\n",
        "#     model.compile(\n",
        "#         optimizer=optimizer,\n",
        "#         loss='mse',  # Mean Squared Error for continuous values\n",
        "#         metrics=['mae']\n",
        "#     )\n",
        "\n",
        "#     return model\n",
        "\n",
        "# # Hyperparameter tuning using RandomSearch\n",
        "# tuner = RandomSearch(\n",
        "#     build_cnn_model,\n",
        "#     objective='val_mae',\n",
        "#     max_trials=10,\n",
        "#     executions_per_trial=1,\n",
        "#     directory='hyperparam_tuning',\n",
        "#     project_name='eeg_risk_prediction_cnn'\n",
        "# )\n",
        "\n",
        "# # Perform tuning\n",
        "# tuner.search(\n",
        "#     X_train_scaled, y_train,\n",
        "#     epochs=50,\n",
        "#     validation_split=0.2,\n",
        "#     batch_size=32,\n",
        "#     callbacks=[EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        "# )\n",
        "\n",
        "# # Get the best hyperparameters\n",
        "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# # Build the best model\n",
        "# best_model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "# # Train the best model\n",
        "# history = best_model.fit(\n",
        "#     X_train_scaled, y_train,\n",
        "#     epochs=100,\n",
        "#     batch_size=32,\n",
        "#     validation_split=0.2,\n",
        "#     callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# # Evaluate on test data\n",
        "# test_loss, test_mae = best_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "# print(f\"\\nTest MAE: {test_mae:.4f}\")\n",
        "\n",
        "# # Predict risk percentage\n",
        "# predictions = best_model.predict(X_test_scaled) * 100  # Convert to percentage\n",
        "\n",
        "# # Save predictions\n",
        "# test_df['predicted_risk_percentage'] = predictions.flatten()\n",
        "# test_df.to_csv(\"eeg_test_predictions.csv\", index=False)\n",
        "\n",
        "# print(\"Predictions saved to 'eeg_test_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX4IMZr4NjFy",
        "outputId": "127a2efe-ec97-489b-92cf-48c55f30c0c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 19s]\n",
            "val_mae: 39.79166793823242\n",
            "\n",
            "Best val_mae So Far: 39.789974212646484\n",
            "Total elapsed time: 00h 04m 07s\n",
            "Epoch 1/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 3228.9380 - mae: 39.5166 - val_loss: 3319.8665 - val_mae: 39.7931\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3219.2703 - mae: 39.5170 - val_loss: 3302.7991 - val_mae: 39.7931\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3202.1057 - mae: 39.5153 - val_loss: 3290.7244 - val_mae: 39.7926\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3193.7192 - mae: 39.5099 - val_loss: 3288.8289 - val_mae: 39.7924\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.9937 - mae: 39.5071 - val_loss: 3288.4678 - val_mae: 39.7922\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.6953 - mae: 39.5073 - val_loss: 3288.3193 - val_mae: 39.7921\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.6250 - mae: 39.5075 - val_loss: 3288.2285 - val_mae: 39.7919\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.5144 - mae: 39.5075 - val_loss: 3288.1768 - val_mae: 39.7919\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.4299 - mae: 39.5071 - val_loss: 3288.1482 - val_mae: 39.7918\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3191.4263 - mae: 39.5075 - val_loss: 3288.1301 - val_mae: 39.7918\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3752 - mae: 39.5070 - val_loss: 3288.1182 - val_mae: 39.7917\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.4043 - mae: 39.5077 - val_loss: 3288.1072 - val_mae: 39.7917\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3862 - mae: 39.5077 - val_loss: 3288.1003 - val_mae: 39.7917\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3635 - mae: 39.5075 - val_loss: 3288.0967 - val_mae: 39.7917\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3650 - mae: 39.5076 - val_loss: 3288.0930 - val_mae: 39.7917\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3826 - mae: 39.5077 - val_loss: 3288.0906 - val_mae: 39.7917\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3623 - mae: 39.5077 - val_loss: 3288.0891 - val_mae: 39.7917\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3352 - mae: 39.5074 - val_loss: 3288.0879 - val_mae: 39.7917\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3525 - mae: 39.5076 - val_loss: 3288.0869 - val_mae: 39.7917\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3330 - mae: 39.5075 - val_loss: 3288.0867 - val_mae: 39.7917\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3350 - mae: 39.5075 - val_loss: 3288.0857 - val_mae: 39.7917\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3416 - mae: 39.5076 - val_loss: 3288.0857 - val_mae: 39.7917\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3191.3374 - mae: 39.5075 - val_loss: 3288.0850 - val_mae: 39.7917\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3550 - mae: 39.5076 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3274 - mae: 39.5075 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3281 - mae: 39.5075 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3318 - mae: 39.5075 - val_loss: 3288.0847 - val_mae: 39.7917\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3284 - mae: 39.5075 - val_loss: 3288.0840 - val_mae: 39.7917\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3315 - mae: 39.5075 - val_loss: 3288.0840 - val_mae: 39.7917\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 3191.3284 - mae: 39.5075 - val_loss: 3288.0840 - val_mae: 39.7917\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3191.3328 - mae: 39.5075 - val_loss: 3288.0837 - val_mae: 39.7917\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3191.3333 - mae: 39.5075 - val_loss: 3288.0837 - val_mae: 39.7917\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3267 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3191.3274 - mae: 39.5074 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3191.3245 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3191.3264 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3191.3252 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3240 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3247 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3191.3240 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3191.3237 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3191.3235 - mae: 39.5074 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3191.3252 - mae: 39.5075 - val_loss: 3288.0833 - val_mae: 39.7917\n",
            "\n",
            "Test MAE: 40.3000\n",
            "\u001b[1m1/8\u001b[0m \u001b[32m‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 78ms/step"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c2dd4f83e20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Predictions saved to 'eeg_test_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, Attention, Multiply\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Data\n",
        "train_df = pd.read_csv(\"train_set.csv\")\n",
        "test_df = pd.read_csv(\"test_set.csv\")\n",
        "\n",
        "# Feature Engineering\n",
        "def engineer_features(df):\n",
        "    feature_columns = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "    df['theta_alpha_ratio'] = df['theta_power'] / df['alpha_power']\n",
        "    df['alpha_beta_ratio'] = df['alpha_power'] / df['beta_power']\n",
        "    df['delta_theta_ratio'] = df['delta_power'] / df['theta_power']\n",
        "    df['beta_gamma_ratio'] = df['beta_power'] / df['gamma_power']\n",
        "\n",
        "    total_power = df[feature_columns].sum(axis=1)\n",
        "    for band in feature_columns:\n",
        "        df[f'relative_{band}'] = df[band] / total_power\n",
        "\n",
        "    df['alpha_theta_diff'] = df['alpha_power'] - df['theta_power']\n",
        "    df['beta_alpha_diff'] = df['beta_power'] - df['alpha_power']\n",
        "    df['mean_power'] = df[feature_columns].mean(axis=1)\n",
        "    df['std_power'] = df[feature_columns].std(axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = engineer_features(train_df)\n",
        "test_df = engineer_features(test_df)\n",
        "\n",
        "# Feature Selection\n",
        "feature_columns = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power',\n",
        "                   'theta_alpha_ratio', 'alpha_beta_ratio', 'delta_theta_ratio', 'beta_gamma_ratio',\n",
        "                   'relative_delta_power', 'relative_theta_power', 'relative_alpha_power',\n",
        "                   'relative_beta_power', 'relative_gamma_power',\n",
        "                   'alpha_theta_diff', 'beta_alpha_diff', 'mean_power', 'std_power']\n",
        "\n",
        "X_train = train_df[feature_columns].values\n",
        "X_test = test_df[feature_columns].values\n",
        "y_train = train_df['risk_percentage'].values / 100  # Normalize [0,1]\n",
        "y_test = test_df['risk_percentage'].values / 100\n",
        "\n",
        "# Scaling Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for LSTM (samples, timesteps=1, features)\n",
        "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Build LSTM Model with Attention\n",
        "def build_lstm_model():\n",
        "    input_layer = Input(shape=(1, X_train_scaled.shape[2]))\n",
        "\n",
        "    # BiLSTM Layer\n",
        "    lstm_out = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2))(input_layer)\n",
        "\n",
        "    # Attention Mechanism\n",
        "    query = Dense(256, activation=\"tanh\")(lstm_out)  # Ensure query matches LSTM output\n",
        "    attention = Attention()([query, lstm_out])\n",
        "    context_vector = Multiply()([attention, lstm_out])\n",
        "\n",
        "    # Second BiLSTM Layer\n",
        "    lstm_out2 = Bidirectional(LSTM(64, return_sequences=False, dropout=0.2))(context_vector)\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    dense_out = Dense(64, activation='relu')(lstm_out2)\n",
        "    dropout_out = Dropout(0.3)(dense_out)\n",
        "    output_layer = Dense(1, activation='sigmoid')(dropout_out)  # Output risk percentage\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize and Train Model\n",
        "model = build_lstm_model()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"\\nTest MAE: {test_mae:.4f} (Lower is better)\")\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test_scaled) * 100  # Convert back to percentage scale\n",
        "\n",
        "# Save Model & Predictions\n",
        "model.save(\"eeg_risk_prediction_lstm.h5\")\n",
        "\n",
        "predictions_df = pd.DataFrame({\"Actual\": y_test * 100, \"Predicted\": y_pred.flatten()})\n",
        "predictions_df.to_csv(\"predictions.csv\", index=False)\n",
        "\n",
        "print(\"Model training complete. Predictions saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOHmL-riOTaK",
        "outputId": "30a94648-a355-44b0-b3d7-d79ed211f1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.3970 - mae: 0.3970 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/ops/nn.py:907: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 39ms/step - loss: 0.3968 - mae: 0.3968 - val_loss: 0.4002 - val_mae: 0.4002\n",
            "Epoch 2/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3911 - mae: 0.3911 - val_loss: 0.4008 - val_mae: 0.4008\n",
            "Epoch 3/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3862 - mae: 0.3862 - val_loss: 0.4005 - val_mae: 0.4005\n",
            "Epoch 4/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.3839 - mae: 0.3839 - val_loss: 0.3882 - val_mae: 0.3882\n",
            "Epoch 5/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.3722 - mae: 0.3722 - val_loss: 0.3565 - val_mae: 0.3565\n",
            "Epoch 6/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3346 - mae: 0.3346 - val_loss: 0.3521 - val_mae: 0.3521\n",
            "Epoch 7/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.3083 - mae: 0.3083 - val_loss: 0.3493 - val_mae: 0.3493\n",
            "Epoch 8/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3148 - mae: 0.3148 - val_loss: 0.3469 - val_mae: 0.3469\n",
            "Epoch 9/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.3126 - mae: 0.3126 - val_loss: 0.3451 - val_mae: 0.3451\n",
            "Epoch 10/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.3077 - mae: 0.3077 - val_loss: 0.3425 - val_mae: 0.3425\n",
            "Epoch 11/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.3190 - mae: 0.3190 - val_loss: 0.3412 - val_mae: 0.3412\n",
            "Epoch 12/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2910 - mae: 0.2910 - val_loss: 0.3410 - val_mae: 0.3410\n",
            "Epoch 13/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3109 - mae: 0.3109 - val_loss: 0.3400 - val_mae: 0.3400\n",
            "Epoch 14/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3172 - mae: 0.3172 - val_loss: 0.3360 - val_mae: 0.3360\n",
            "Epoch 15/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2762 - mae: 0.2762 - val_loss: 0.3379 - val_mae: 0.3379\n",
            "Epoch 16/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3036 - mae: 0.3036 - val_loss: 0.3355 - val_mae: 0.3355\n",
            "Epoch 17/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3181 - mae: 0.3181 - val_loss: 0.3309 - val_mae: 0.3309\n",
            "Epoch 18/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.3015 - mae: 0.3015 - val_loss: 0.3332 - val_mae: 0.3332\n",
            "Epoch 19/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.3044 - mae: 0.3044 - val_loss: 0.3376 - val_mae: 0.3376\n",
            "Epoch 20/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2879 - mae: 0.2879 - val_loss: 0.3370 - val_mae: 0.3370\n",
            "Epoch 21/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.3047 - mae: 0.3047 - val_loss: 0.3332 - val_mae: 0.3332\n",
            "Epoch 22/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.2988 - mae: 0.2988 - val_loss: 0.3281 - val_mae: 0.3281\n",
            "Epoch 23/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.3041 - mae: 0.3041 - val_loss: 0.3258 - val_mae: 0.3258\n",
            "Epoch 24/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2885 - mae: 0.2885 - val_loss: 0.3351 - val_mae: 0.3351\n",
            "Epoch 25/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2857 - mae: 0.2857 - val_loss: 0.3381 - val_mae: 0.3381\n",
            "Epoch 26/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2944 - mae: 0.2944 - val_loss: 0.3328 - val_mae: 0.3328\n",
            "Epoch 27/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.2825 - mae: 0.2825 - val_loss: 0.3213 - val_mae: 0.3213\n",
            "Epoch 28/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2828 - mae: 0.2828 - val_loss: 0.3166 - val_mae: 0.3166\n",
            "Epoch 29/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.2755 - mae: 0.2755 - val_loss: 0.3187 - val_mae: 0.3187\n",
            "Epoch 30/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2876 - mae: 0.2876 - val_loss: 0.3120 - val_mae: 0.3120\n",
            "Epoch 31/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2872 - mae: 0.2872 - val_loss: 0.3089 - val_mae: 0.3089\n",
            "Epoch 32/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.3110 - mae: 0.3110 - val_loss: 0.3058 - val_mae: 0.3058\n",
            "Epoch 33/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 0.3081 - mae: 0.3081 - val_loss: 0.3024 - val_mae: 0.3024\n",
            "Epoch 34/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.2753 - mae: 0.2753 - val_loss: 0.3102 - val_mae: 0.3102\n",
            "Epoch 35/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.2914 - mae: 0.2914 - val_loss: 0.3123 - val_mae: 0.3123\n",
            "Epoch 36/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2847 - mae: 0.2847 - val_loss: 0.3028 - val_mae: 0.3028\n",
            "Epoch 37/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.2837 - mae: 0.2837 - val_loss: 0.3032 - val_mae: 0.3032\n",
            "Epoch 38/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2913 - mae: 0.2913 - val_loss: 0.3043 - val_mae: 0.3043\n",
            "Epoch 39/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.2920 - mae: 0.2920 - val_loss: 0.3062 - val_mae: 0.3062\n",
            "Epoch 40/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2872 - mae: 0.2872 - val_loss: 0.3089 - val_mae: 0.3089\n",
            "Epoch 41/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2791 - mae: 0.2791 - val_loss: 0.3101 - val_mae: 0.3101\n",
            "Epoch 42/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.2897 - mae: 0.2897 - val_loss: 0.3090 - val_mae: 0.3090\n",
            "Epoch 43/100\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.2902 - mae: 0.2902 - val_loss: 0.3064 - val_mae: 0.3064\n",
            "\n",
            "Test MAE: 0.3081 (Lower is better)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78ebc0c48f40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete. Predictions saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, LayerNormalization, Multiply, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Data\n",
        "train_df = pd.read_csv(\"train_set.csv\")\n",
        "test_df = pd.read_csv(\"test_set.csv\")\n",
        "\n",
        "# Feature Engineering\n",
        "def engineer_features(df):\n",
        "    feature_columns = ['delta_power', 'theta_power', 'alpha_power', 'beta_power', 'gamma_power']\n",
        "    df['theta_alpha_ratio'] = df['theta_power'] / df['alpha_power']\n",
        "    df['alpha_beta_ratio'] = df['alpha_power'] / df['beta_power']\n",
        "    df['delta_theta_ratio'] = df['delta_power'] / df['theta_power']\n",
        "    df['beta_gamma_ratio'] = df['beta_power'] / df['gamma_power']\n",
        "\n",
        "    total_power = df[feature_columns].sum(axis=1)\n",
        "    for band in feature_columns:\n",
        "        df[f'relative_{band}'] = df[band] / total_power\n",
        "\n",
        "    df['alpha_theta_diff'] = df['alpha_power'] - df['theta_power']\n",
        "    df['beta_alpha_diff'] = df['beta_power'] - df['alpha_power']\n",
        "    df['mean_power'] = df[feature_columns].mean(axis=1)\n",
        "    df['std_power'] = df[feature_columns].std(axis=1)\n",
        "    df['power_skewness'] = df[feature_columns].skew(axis=1)\n",
        "    df['power_kurtosis'] = df[feature_columns].kurtosis(axis=1)\n",
        "\n",
        "    return df\n",
        "\n",
        "train_df = engineer_features(train_df)\n",
        "test_df = engineer_features(test_df)\n",
        "\n",
        "# Feature Selection\n",
        "feature_columns = train_df.columns.difference(['risk_percentage'])\n",
        "X_train = train_df[feature_columns].values\n",
        "X_test = test_df[feature_columns].values\n",
        "y_train = train_df['risk_percentage'].values / 100  # Normalize [0,1]\n",
        "y_test = test_df['risk_percentage'].values / 100\n",
        "\n",
        "# Scaling Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Reshape for LSTM\n",
        "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "class RepeatLayer(Layer):\n",
        "    def __init__(self, repeats, axis, **kwargs):\n",
        "        super(RepeatLayer, self).__init__(**kwargs)\n",
        "        self.repeats = repeats\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.repeat(inputs, repeats=self.repeats, axis=self.axis)\n",
        "\n",
        "# Custom Scaled Dot-Product Attention Layer\n",
        "class ScaledDotProductAttentionLayer(Layer):\n",
        "    def call(self, inputs):\n",
        "        query, key, value = inputs\n",
        "        scores = tf.matmul(query, key, transpose_b=True) / tf.math.sqrt(tf.cast(tf.shape(key)[-1], tf.float32))\n",
        "        weights = tf.nn.softmax(scores, axis=-1)\n",
        "        return tf.matmul(weights, value)\n",
        "\n",
        "# Build Optimized LSTM Model\n",
        "def build_lstm_model():\n",
        "    input_layer = Input(shape=(1, X_train_scaled.shape[2]))\n",
        "\n",
        "    # BiLSTM Layer\n",
        "    lstm_out = Bidirectional(LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(input_layer)\n",
        "\n",
        "    # Ensure Query, Key, and Value match LSTM output shape\n",
        "    query = Dense(128)(lstm_out)  # Changed Dense units to 128\n",
        "    key = Dense(128)(lstm_out)  # Changed Dense units to 128\n",
        "    value = Dense(128)(lstm_out)  # Changed Dense units to 128\n",
        "    attention_output = ScaledDotProductAttentionLayer()([query, key, value])\n",
        "\n",
        "    # Align dimensions before multiplication\n",
        "    # context_vector = Multiply()([attention_output, lstm_out]) # This line produced the error\n",
        "    # Correcting the shape of attention output:\n",
        "    attention_output_repeated = RepeatLayer(repeats=2, axis=2)(attention_output)\n",
        "    context_vector = Multiply()([attention_output_repeated, lstm_out])\n",
        "\n",
        "    # Second BiLSTM Layer\n",
        "    lstm_out2 = Bidirectional(LSTM(64, return_sequences=False, dropout=0.3, recurrent_dropout=0.3))(context_vector)\n",
        "\n",
        "    # Normalization & Dense Layers\n",
        "    norm_out = LayerNormalization()(lstm_out2)\n",
        "    dense_out = Dense(64, activation='relu')(norm_out)\n",
        "    dropout_out = Dropout(0.4)(dense_out)\n",
        "    output_layer = Dense(1, activation='sigmoid')(dropout_out)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005), loss=tf.keras.losses.Huber(), metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train Model\n",
        "model = build_lstm_model()\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_scaled, y_train,\n",
        "    epochs=150,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"\\nTest MAE: {test_mae:.4f} (Lower is better)\")\n",
        "\n",
        "# Make Predictions\n",
        "y_pred = model.predict(X_test_scaled) * 100\n",
        "\n",
        "# Save Model & Predictions\n",
        "model.save(\"optimized_eeg_lstm.h5\")\n",
        "predictions_df = pd.DataFrame({\"Actual\": y_test * 100, \"Predicted\": y_pred.flatten()})\n",
        "predictions_df.to_csv(\"optimized_predictions.csv\", index=False)\n",
        "\n",
        "print(\"Optimized model training complete. Predictions saved.\")\n"
      ],
      "metadata": {
        "id": "f1Jc3qY1-CBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473ab288-7ea4-483f-e47a-3c259b654989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 80ms/step - loss: 0.0923 - mae: 0.3971 - val_loss: 0.0913 - val_mae: 0.4016\n",
            "Epoch 2/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0879 - mae: 0.3917 - val_loss: 0.0925 - val_mae: 0.4016\n",
            "Epoch 3/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0872 - mae: 0.3894 - val_loss: 0.0912 - val_mae: 0.3977\n",
            "Epoch 4/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0815 - mae: 0.3740 - val_loss: 0.0900 - val_mae: 0.3929\n",
            "Epoch 5/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0818 - mae: 0.3724 - val_loss: 0.0883 - val_mae: 0.3837\n",
            "Epoch 6/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0821 - mae: 0.3678 - val_loss: 0.0881 - val_mae: 0.3797\n",
            "Epoch 7/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0782 - mae: 0.3539 - val_loss: 0.0891 - val_mae: 0.3757\n",
            "Epoch 8/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0794 - mae: 0.3527 - val_loss: 0.0868 - val_mae: 0.3692\n",
            "Epoch 9/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0791 - mae: 0.3531 - val_loss: 0.0858 - val_mae: 0.3659\n",
            "Epoch 10/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0739 - mae: 0.3374 - val_loss: 0.0839 - val_mae: 0.3583\n",
            "Epoch 11/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0844 - mae: 0.3629 - val_loss: 0.0867 - val_mae: 0.3639\n",
            "Epoch 12/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0788 - mae: 0.3496 - val_loss: 0.0850 - val_mae: 0.3598\n",
            "Epoch 13/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0777 - mae: 0.3425 - val_loss: 0.0846 - val_mae: 0.3587\n",
            "Epoch 14/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0742 - mae: 0.3365 - val_loss: 0.0832 - val_mae: 0.3531\n",
            "Epoch 15/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0766 - mae: 0.3389 - val_loss: 0.0813 - val_mae: 0.3516\n",
            "Epoch 16/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0787 - mae: 0.3494 - val_loss: 0.0818 - val_mae: 0.3560\n",
            "Epoch 17/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0741 - mae: 0.3389 - val_loss: 0.0816 - val_mae: 0.3533\n",
            "Epoch 18/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0719 - mae: 0.3262 - val_loss: 0.0820 - val_mae: 0.3513\n",
            "Epoch 19/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0738 - mae: 0.3345 - val_loss: 0.0854 - val_mae: 0.3578\n",
            "Epoch 20/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0800 - mae: 0.3496 - val_loss: 0.0819 - val_mae: 0.3549\n",
            "Epoch 21/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0714 - mae: 0.3321 - val_loss: 0.0831 - val_mae: 0.3545\n",
            "Epoch 22/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0705 - mae: 0.3254 - val_loss: 0.0821 - val_mae: 0.3495\n",
            "Epoch 23/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0746 - mae: 0.3324 - val_loss: 0.0826 - val_mae: 0.3504\n",
            "Epoch 24/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0768 - mae: 0.3374 - val_loss: 0.0840 - val_mae: 0.3548\n",
            "Epoch 25/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0710 - mae: 0.3288 - val_loss: 0.0832 - val_mae: 0.3503\n",
            "Epoch 26/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0718 - mae: 0.3260 - val_loss: 0.0850 - val_mae: 0.3545\n",
            "Epoch 27/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0742 - mae: 0.3291 - val_loss: 0.0845 - val_mae: 0.3543\n",
            "Epoch 28/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0707 - mae: 0.3237 - val_loss: 0.0838 - val_mae: 0.3537\n",
            "Epoch 29/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0684 - mae: 0.3214 - val_loss: 0.0837 - val_mae: 0.3525\n",
            "Epoch 30/150\n",
            "\u001b[1m24/24\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.0696 - mae: 0.3219 - val_loss: 0.0816 - val_mae: 0.3513\n",
            "\n",
            "Test MAE: 0.3438 (Lower is better)\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 186ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized model training complete. Predictions saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GjrQwNG4pYw2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}